\section{Integration Problem Statement}
Splice Machine's HBase data needs to be accessible to analytical engines that are capable of accessing
Hadoop input and output formats and hive related serde structures.  HBase's
default approach to split based on region and to scan the data remotely from
hbase into the analytic's process has been a significant impediment to utilizing
analytics engines with HBase.

\subsection{Optimized Analytical Reader for HBase}
Facebook Analytics team was the first team to scan store files directly for an
OLAP use case.  The process required a flush of the memstore of each region and
expected no concurrent writes.  Their approach while illustrative tears at the
very purpose of Splice Machine (Hadoop Concurrency).  The following subsections
will lay out a novel approach to addressing concurrency while providing a
scalable analytics approach for various processes and tools.

\subsubsection{Direct Store File Access}
Accessing store files directly allows analytical systems to bypass the following
issues when accessing HBase via Large Full Table Scans:

\begin{enumerate}
	\item The Single JVM block loading model puts significant heap pressure on the
	HBase process.
	\item Using RPC to access the data limits the througput of the scans returning
	from HBase by requiring multiple serialization points and 
	synchronization barriers.
	\item The analytical resources required (CPU/IO) are not isolated to the
	analytical process and cannot be prioritized against HBase workloads.
\end{enumerate}


HBase already has API's that support accessing an HBase Region
directly from the corresponding store files at different levels of access.  The
highest level is the ClientSideRegionScanner.  This class listed below basically
allows for creating a scanner on the store files by themselves.

\begin{lstlisting}[language=java]

package com.splicemachine.mrio.api;

/**
 * A client scanner for a region opened for read-only on the client side. Assumes region data
 * is not changing.
 */
@InterfaceAudience.Private
public class ClientSideRegionScanner extends AbstractClientScanner {

\end{lstlisting}

This external API swallows one of the most important pieces of functionality
that Regions can perform, that of a store scan merged with a memory based
scanner during scanner creation.  The key is to wrap the scanner creation piece
inside your own implementation of ClientSideRegionScanner.  

\begin{lstlisting}[language=java]
  
  public class HRegion implements HeapSize {

  public static HRegion openHRegion(final Configuration conf, final FileSystem fs,
      final Path rootDir, final HRegionInfo info, final HTableDescriptor htd, final HLog wal,
      final RegionServerServices rsServices, final CancelableProgressable reporter)
      throws IOException {
    Path tableDir = FSUtils.getTableDir(rootDir, info.getTable());
    return openHRegion(conf, fs, rootDir, tableDir, info, htd, wal, rsServices, reporter);
  }
\end{lstlisting}

\subsubsection{Memstore Only Access}
The data available via the Store File Access approach currently has the
following limitations.

\begin{enumerate}
	\item Data Available in the memstore will be omitted from the scan.
	\item Splits could cause issues with region availability.
\end{enumerate}

HBase has a partial implementation of a memstore only scanner that can be used
with a few patches to the InternalScan Implementation.  A memstore only scan is
attached below with an attribute determining whether the scan logic should go
against the memstore only.

\begin{lstlisting}[language=java]

public class SpliceIndexObserver extends AbstractSpliceIndexObserver {

	@Override
	public KeyValueScanner preStoreScannerOpen(
			ObserverContext<RegionCoprocessorEnvironment> c, Store store,
			Scan scan, NavigableSet<byte[]> targetCols, KeyValueScanner s)
			throws IOException {
		if (scan.getAttribute("MR") != null) {
			System.out.println("booh");
			InternalScan iscan = new InternalScan(scan);
			iscan.checkOnlyMemStore();
		      return new StoreScanner(store, store.getScanInfo(), iscan, targetCols,
		    	        ((HStore)store).getHRegion().getReadpoint(IsolationLevel.READ_UNCOMMITTED));		
		} 
		return super.preStoreScannerOpen(c, store, scan, targetCols, s);
	}
\end{lstlisting}

Once you have the memstore only scan, the scan needs to be merged back into the
StoreScanner.  To do this, you first must implement a KeyValueScanner interface
that wraps the external memstore only scan.

\begin{lstlisting}[language=java]

public class SpliceMemstoreKeyValueScanner implements KeyValueScanner,
InternalScanner {
\end{lstlisting}

Once this interface is implemented, the next step would be to merge those
results back into the StoreScanner.

\begin{lstlisting}[language=java]

public class SpliceClientSideRegionScanner implements RegionScanner {
  protected HRegion region;
  protected RegionScanner scanner;

  public SpliceClientSideRegionScanner(Configuration conf, FileSystem fs,
      Path rootDir, HTableDescriptor htd, HRegionInfo hri, Scan scan, ScanMetrics scanMetrics, List<KeyValueScanner> keyValueScanners) throws IOException {
    scan.setIsolationLevel(IsolationLevel.READ_UNCOMMITTED);     // region is immutable, set isolation level
    this.region = HRegion.openHRegion(conf, fs, rootDir, hri, htd, null, null, null);
    this.scanner = BaseHRegionUtil.getScanner(region, scan, keyValueScanners);
    region.startRegionOperation();
  }

\end{lstlisting}

\subsubsection{Deterministic Input Splits}
HBase's current TableSplit implementation splits via region.  Splice Machine has
found this not to be desirable since the region size can be highly variable. 
The goal would be to have this input split a configurable number of HBase
Blocks (Bytes).  Example code can be found in the HRegionUtil.getBlocksToRead
method.

\subsubsection{Accurate Concurrent Splice Record Reader}
Even though we can create a scanner that has both the memstore and the store
file scanner, there is still a need for a wrapper mechanism for the case where
there is a split of the region in between computing the input splits and executing the
task.  In this case, we need to have a scanner that can combine N regions and
act on them as if they are one task.  Example code can be found in
SplitRegionScanner.

\subsubsection{Hive SerDe}

Please see Yannan's prior work.  Splice Machine will still need a Serde with
hive but should use the InputFormat above.  TODO

%End Integration Chapter