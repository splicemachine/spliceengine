\section{Spark Integration with HBase: Representing Log Structured Merge Trees
with a Directed Acyclic Graph}
The merging of an LSM tree (immutable data structures) with a Directed Acyclic
Graph should yield significant performance capabilities over simply rescanning
all the data out of the LSM tree for each execution.  

\subsection{Splice Explain Plan Transformed from LSM to Performant DAG
Structure} This section will go through a simple splice explain plan and then
view it in the current DAG structure and the proposed DAG structure.

\subsubsection{Splice Explain Tree}
Here is the explain plan for a simple 3 way inner join.

\tikzstyle{abstract}=[rectangle, draw=black, rounded corners, fill=blue!20, drop shadow, text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{comment}=[rectangle, draw=black, rounded corners, fill=green, drop shadow,
        text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{myarrow}=[->, >=open triangle 90, thick]
\tikzstyle{line}=[-, thick]
        
\begin{center}
\begin{tikzpicture}[node distance=0.4cm]
    \node (Table1) [abstract, rectangle split, rectangle split parts=1] {
            \textbf{$Table_{1}$}
        };
    \node (Join1) [abstract, rectangle split, rectangle split parts=1,    
    above right=of Table1] {
            \textbf{$Join_{1}$}
        };
    \node (Table2) [abstract, rectangle split, rectangle split
    parts=1,below right=of Join1] {
            \textbf{$Table_{2}$}
        };
    \node (Projection1) [abstract, rectangle split, rectangle split parts=1,    
        above right=of Join1] {
                    \textbf{$Projection_{1}$}
        };
    \node (Join2) [abstract, rectangle split, rectangle split parts=1,    
        above right=of Projection1] {
            \textbf{$Join_{2}$}
        };
    \node (Table3) [abstract, rectangle split, rectangle split parts=1,    
        below right=of Join2] {
        \textbf{$Table_{3}$}
        };
        
         \path (Table1) edge (Join1);
         \path (Join1) edge (Projection1);
         \path (Join1) edge (Table2);
         \path (Projection1) edge (Join2);
         \path (Join2) edge (Table3);
\end{tikzpicture}
\end{center}

\subsubsection{Current DAG Model}
Here is the current DAG model based on the current thinking on HBase integration
with Spark via Hadoop Input Formats.

\tikzstyle{abstract}=[rectangle, draw=black, rounded corners, fill=blue!20, drop shadow, text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{comment}=[rectangle, draw=black, rounded corners, fill=green, drop shadow, text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{myarrow}=[->, >=open triangle 90, thick]
\tikzstyle{line}=[-, thick]
        
\begin{center}
\begin{tikzpicture}[node distance=0.4cm]
    \node (Table1) [abstract, rectangle split, rectangle split parts=2] {
            \textbf{$Table_{1}$}
            \nodepart{second}Region Based RDD
        };
    \node (Join1) [abstract, rectangle split, rectangle split parts=2,    
    above right=of Table1] {
            \textbf{$Join_{1}$}
            \nodepart{second}Post Join RDD
        };
    \node (Table2) [abstract, rectangle split, rectangle split
    parts=2,below right=of Join1] {
            \textbf{$Table_{2}$}
            \nodepart{second}Region Based RDD
        };
    \node (Projection1) [abstract, rectangle split, rectangle split parts=1,    
        above right=of Join1] {
                    \textbf{$Projection_{1}$}
        };
    \node (Join2) [abstract, rectangle split, rectangle split parts=2,    
        above right=of Projection1] {
            \textbf{$Join_{2}$}
            \nodepart{second}Post Join RDD
        };
    \node (Table3) [abstract, rectangle split, rectangle split parts=2,    
        below right=of Join2] {
        \textbf{$Table_{3}$}
        \nodepart{second}Region Based RDD
        };
        
         \path (Table1) edge (Join1);
         \path (Join1) edge (Projection1);
         \path (Join1) edge (Table2);
         \path (Projection1) edge (Join2);
         \path (Join2) edge (Table3);


%        
%        
        
\end{tikzpicture}
\end{center}

This approach has several significant pitfalls listed below:

\begin{enumerate}
	\item Scan Based RDD: Each individual scan against the data constructs a
	different RDD based on the regions, filters, and fields participating.
	\item Data Movement: The entire HBase results for the table scans must be
	externally scanned (scan local to node but still external to process) and
	transferred to the DAG model during each execution.  This causes all members of
	the graph to be impossible to reuse.
	\item Snapshot Isolation Application: Since Snapshot Isolation is applied in
	HBase, each read from the HBase table could have a slightly smaller 
	\item Updates:  A single update to a region will cause the DAG model to re-read
	all regions for that table.  For example, you have 1TB of data and a single
	update will require you to re-read the 1TB of data.
\end{enumerate}

\subsubsection{Proposed Simple DAG Model}
Here is the proposed Simple DAG model based on trying to limit the amount of
data needed to be read from HBase.  The changes are centered around the
interaction with HBase Tables.  The remainder of the plan tree will be discarded
for this analysis.

\tikzstyle{abstract}=[rectangle, draw=black, rounded corners, fill=blue!20, drop shadow, text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{comment}=[rectangle, draw=black, rounded corners, fill=green, drop shadow,
        text centered, anchor=north, text=white, text width=3cm]
\tikzstyle{myarrow}=[->, >=open triangle 90, thick]
\tikzstyle{line}=[-, thick]
        
\begin{center}
\begin{tikzpicture}[node distance=0.4cm]
    \node (Table1) [abstract, rectangle split, rectangle split parts=2] {
            \textbf{$Table_{1}$}
            \nodepart{second}No RDD, Just Scan Logic
        };

    \node (Table1Region1) [abstract, rectangle split, rectangle split parts=2,    
    below left=of Table1] {
            \textbf{$Table_{1}$$Region_{1}$}
            \nodepart{second}RDD
        };

    \node (Table1RegionN) [abstract, rectangle split, rectangle split parts=2,    
    below right=of Table1] {
            \textbf{$Table_{1}$$Region_{n}$}
            \nodepart{second}RDD
        };

        
         \path (Table1RegionN) edge (Table1);
         \path (Table1Region1) edge (Table1);

\end{tikzpicture}
\end{center}

\begin{enumerate}
	\item Scan Based RDD: Scans will go against the same cached RDD for evaluation.
	\item Data Movement: Only regions with updated data will invalidate the RDD and
	force a reload.
	\item Snapshot Isolation Application: Cache all KeyValue objects on the RDD and 
	perform the filtering on Spark given a specific transaction
	\item Updates:  A single update to a region will cause the DAG model to re-read
	that single regions for that table (1 Gig).  For example, you have 1TB of data
	and a single update will require you to re-read only 1GB of data.
\end{enumerate}
        

\subsubsection{Handling HBase operations}

\begin{enumerate}
	\item Write: invalidate RDD for given region.
	\item Region movement: invalidate RDD, the new RDD will be collocated 
	in the new server
	\item Split: invalidate RDD, next query will have one RDD per region
\end{enumerate}
        
        
\subsubsection{RDD Creation}

RDD are controlled (created and used) by the Spark driver, i.e. the client submitting the 
Spark job. This is going to be the Splice driver that is running the query, which is located 
on an arbitrary server.
Since RDDs are located on the clients, there are two options to invalidate them from the server:

 \begin{enumerate}
	\item Invalidate all RDDs dependent on that region remotely and synchronously: 
	adds lots of latency for all HBase operations (writes, splits, compactions, etc.)
	\item Keep invalidation info on servers, invalidate locally: adds some latency for queries,
	DAG creation has to check for RDD invalidation. 
\end{enumerate}
        
We'll use option \#2, since it doesn't hurt updates performance and just adds a small 
latency for queries (see figure~\ref{fig:cache}). We could avoid the extra roundtrip 
entirely with a customized \verb|InputFormat|, but this needs some research // TODO investigate this dgf

\begin{figure}[h]
\begin{sequencediagram}
\newthread {cl}{Client}
\newthread {c}{RDDCache}
\newinst [2] {s}{Server}
\begin{messcall}{cl}{getRDD()}{c}
\begin{call}{c}{ hasCachedRDD() }{c}{cached}
\end{call}
\begin{sdblock}{NotCached}{}
\begin{call}{c}{ createRDD() }{s}{RDD}
\end{call}
\mess{c}{RDD}{cl}
\end{sdblock}
\begin{sdblock}{Cached}{}
\begin{call}{c}{ isCachedRDDValid() }{s}{valid}
\end{call}

\begin{sdblock}{NotValid}{}
\begin{call}{c}{ createRDD() }{s}{RDD}
\end{call}
\mess{c}{RDD}{cl}
\end{sdblock}
\begin{sdblock}{Valid}{}
\begin{call}{c}{ getCachedRDD() }{c}{RDD}
\end{call}
\mess{c}{RDD}{cl}
\end{sdblock}

\end{sdblock}
\end{messcall}
\end{sequencediagram}
 \caption{RDD cache creation/invalidation}
\label{fig:cache}
\end{figure}

      
\subsection{Snapshot Isolation in Spark}

Several transactions could be accessing the same data concurrently (possible running 
different queries). If we want to effectively use Spark we must share the cached data 
across the different transactions. For this to work, we must implement Snapshot Isolation 
on Spark, thus requiring the cache to hold all KV's for a given region:
 \begin{enumerate}
	\item All 'active' versions of the same row
	\item Commit timestamps
	\item Tombstones
\end{enumerate}

Each query will retain the KVs that directly affect the transaction, filtering out all the 
remaining KVs. This filtering has a cost but we'll be able to share the cache 
much more effectively.

\subsection{Internal Spark representation}

We must cache all KV in Spark in order to implement Snapshot Isolation but we could choose
 a different representation inside Spark (instead of storing KV objects). This is a longer term goal.

Options:
 \begin{enumerate}
	\item Store one KV (or another type of object) per version, instead of having one KV 
	per version and per data type (value, commit timestamp, tombstone...)
	\item Columnar representation
\end{enumerate}

See figure~\ref{fig:rdd}.

\begin{figure}[h]
\begin{sequencediagram}
\newthread {c}{RDDCache}
\newinst [2] {s}{RegionServer}
\newinst [2] {s2}{RegionServer2}

\begin{call}{c}{ createRDD(region) }{s}{RDD}
	\begin{sdblock}{Read Loop}{}
		\begin{call}{s}{ readKV() }{s}{KV}

			\begin{sdblock}{If No Commit Timestamp}{}
				\begin{call}{s}{ resolveCommitStatus() }{s2}{commitStatus}
				\end{call}
			\end{sdblock}

		\end{call}
	\end{sdblock}
\end{call}

	\begin{sdblock}{Transform Loop}{Optional}
		\begin{call}{c}{ transformKV() }{c}{cachedRow/Column}
		\end{call}
	\end{sdblock}

\end{sequencediagram}
 \caption{RDD creation}
\label{fig:rdd}
\end{figure}

      
\subsection{Spark execution}

The execution in Spark works as follows:

 \begin{enumerate}
	\item Transform Derby/Splice execution plan into Spark DAG
	 \begin{enumerate}
		\item Each Derby/Splice operation will be implemented by Spark operations
		\item Each accessed table will be represented by several RDDs, one per region
		\item Region RDDs will be cached, reused and combined to represent each table
	\end{enumerate}
	\item The job will be submitted to the Spark cluster and executed
	 \begin{enumerate}
		\item Cached RDDs will be readily available in memory
		\item Uncached RDDs will be created from scratch: 
		a scanner will be opened from the Spark worker and bring the region 
		into memory
	\end{enumerate}
\end{enumerate}


\begin{figure}[h]
\begin{sequencediagram}
\newthread {j}{JDBC}
\newinst [2] {d}{Derby}
\newinst {c}{RDDCache}
\newthread {sm}{SparkMaster}
\newthread {sw1}{SparkWorker1}
\newthread {sw2}{SparkWorker2}
\newinst {rs}{RegionServer}

\begin{call}{j}{executeQuery(query)}{d}{results}

\begin{call}{d}{preparePlan(query)}{d}{plan}\end{call}
\begin{call}{d}{generateSparkJob(plan)}{d}{sparkJob}
	\begin{sdblock}{For Each Operation}{}
		\begin{call}{d}{generateSparkOperation(plan)}{d}{op}\end{call}
		\begin{call}{d}{getRDD()}{c}{RDD}\end{call}
	\end{sdblock}
\end{call}
	\begin{sdblock}{Scheduling}{}
\mess{d}{submitSparkJob}{sm}
		\mess{sm}{ submitTask}{sw1}

			\begin{sdblock}{Cached RDD}{}
				\begin{call}{sw1}{ getCachedRDD() }{sw1}{RDD}
				\end{call}
			\end{sdblock}

			\mess{sw1}{result}{d}

		
		\mess{sm}{ submitTask }{sw2}

			\begin{sdblock}{Non-Cached RDD}{}
				\begin{call}{sw2}{ openScanner() }{rs}{KVs}
				\end{call}
			\end{sdblock}

			\mess{sw2}{result}{d}

	\end{sdblock}

\end{call}
\end{sequencediagram}
 \caption{RDD creation}
\label{fig:rdd}
\end{figure}





%End LSM to DAG chapter
