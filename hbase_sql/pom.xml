<?xml version="1.0" encoding="UTF-8"?>
<!--
  ~ Copyright (c) 2012 - 2019 Splice Machine, Inc.
  ~
  ~ This file is part of Splice Machine.
  ~ Splice Machine is free software: you can redistribute it and/or modify it under the terms of the
  ~ GNU Affero General Public License as published by the Free Software Foundation, either
  ~ version 3, or (at your option) any later version.
  ~ Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;
  ~ without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
  ~ See the GNU Affero General Public License for more details.
  ~ You should have received a copy of the GNU Affero General Public License along with Splice Machine.
  ~ If not, see <http://www.gnu.org/licenses/>.
  -->
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
    <modelVersion>4.0.0</modelVersion>
    <artifactId>hbase_sql</artifactId>
    <description>SQL engine based on HBase</description>
    <parent>
        <artifactId>spliceengine-parent</artifactId>
        <groupId>com.splicemachine</groupId>
        <version>3.1.0.1943-SNAPSHOT</version>
    </parent>
    <properties>
        <argLine>-Xmx4g ${jacocoAgent}</argLine>
    </properties>

    <dependencies>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>db-engine</artifactId>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>splice_machine</artifactId>
            <version>${project.version}</version>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>hbase_storage</artifactId>
            <version>${project.version}</version>
            <classifier>${envClassifier}</classifier>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
	    <artifactId>scala_util</artifactId>
            <version>${project.version}</version>
	    <classifier>${envClassifier}-${spark.version}_${scala.binary.version}</classifier>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>hbase_pipeline</artifactId>
            <version>${project.version}</version>
            <classifier>${envClassifier}</classifier>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>splice_aws</artifactId>
            <version>${project.version}</version>
            <classifier>shade</classifier>
        </dependency>
        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>spark_sql</artifactId>
            <version>${project.version}</version>
            <classifier>${envClassifier}</classifier>
        </dependency>
        <dependency>
            <groupId>com.typesafe.akka</groupId>
            <artifactId>akka-remote_${scala.binary.version}</artifactId>
            <version>2.4.8</version>
        </dependency>
        <dependency>
            <groupId>io.airlift</groupId>
            <artifactId>units</artifactId>
            <version>1.0</version>
        </dependency>
        <dependency>
            <groupId>io.airlift</groupId>
            <artifactId>log</artifactId>
            <version>0.144</version>
        </dependency>
        <dependency>
            <groupId>io.airlift</groupId>
            <artifactId>stats</artifactId>
            <version>0.144</version>
        </dependency>
        <dependency>
            <groupId>io.airlift</groupId>
            <artifactId>slice</artifactId>
            <version>0.28</version>
        </dependency>
        <dependency>
            <groupId>com.facebook.presto.orc</groupId>
            <artifactId>orc-protobuf</artifactId>
            <version>1</version>
        </dependency>
        <dependency>
            <!-- com.databricks.spark.avro -->
            <groupId>com.databricks</groupId>
            <artifactId>spark-avro_${scala.binary.version}</artifactId>
            <version>4.0.0</version>
            <scope>runtime</scope>
        </dependency>

        <!-- Provided dependencies -->

        <dependency>
            <groupId>io.netty</groupId>
            <artifactId>netty-all</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>com.google.guava</groupId>
            <artifactId>guava</artifactId>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-common</artifactId>
            <version>${hadoop.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-mapreduce-client-core</artifactId>
            <version>${hadoop.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-yarn-client</artifactId>
            <version>${hadoop.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-client</artifactId>
            <version>${hbase.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>${hbase.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-mllib_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-hive_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>

        <!--Test dependencies -->

        <dependency>
            <groupId>com.splicemachine</groupId>
            <artifactId>splice_machine</artifactId>
            <version>${project.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>${project.groupId}</groupId>
            <artifactId>splice_si_api</artifactId>
            <version>${project.version}</version>
            <type>test-jar</type>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>commons-dbutils</groupId>
            <artifactId>commons-dbutils</artifactId>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>io.airlift</groupId>
            <artifactId>testing</artifactId>
            <version>0.144</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-testing-util</artifactId>
            <version>${hbase.version}</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hive</groupId>
            <artifactId>hive-jdbc</artifactId>
            <version>${hive.version}</version>
            <scope>test</scope>
        </dependency>
    </dependencies>

    <build>
        <plugins>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-jar-plugin</artifactId>
                <configuration>
                    <excludes>
                        <exclude>**/*log4j.properties</exclude>
                    </excludes>
                </configuration>
                <executions>
                    <execution>
                        <id>test-jar</id>
                        <configuration>
                            <classifier>${envClassifier}-tests</classifier>
                        </configuration>
                        <goals>
                            <goal>test-jar</goal>
                        </goals>
                    </execution>
                    <execution>
                        <id>default-jar</id>
                        <configuration>
                            <classifier>${envClassifier}</classifier>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.codehaus.mojo</groupId>
                <artifactId>build-helper-maven-plugin</artifactId>
                <version>1.9.1</version>
                <executions>
                    <execution>
                        <id>add-platform-source</id>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>add-source</goal>
                        </goals>
                        <configuration>
                            <sources>
                                <source>${envHbase}/src/main/java</source>
                                <source>${parquet.version}/src/main/java</source>
                            </sources>
                        </configuration>
                    </execution>
                    <execution>
                        <id>add-platform-test-source</id>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>add-test-source</goal>
                        </goals>
                        <configuration>
                            <sources>
                                <source>${envHbase}/src/test/java</source>
                            </sources>
                        </configuration>
                    </execution>
                    <execution>
                        <id>add-platform-test-resource</id>
                        <phase>generate-sources</phase>
                        <goals>
                            <goal>add-test-resource</goal>
                        </goals>
                        <configuration>
                            <resources>
                                <resource>
                                    <directory>${envHbase}/src/test/resources</directory>
                                </resource>
                            </resources>
                        </configuration>
                    </execution>
                </executions>
            </plugin>
            <plugin>
                <groupId>org.apache.maven.plugins</groupId>
                <artifactId>maven-source-plugin</artifactId>
                <version>2.4</version>
                <configuration>
                    <classifier>${envClassifier}-sources</classifier>
                </configuration>
            </plugin>
        </plugins>
        <resources>
            <resource>
                <directory>${envHbase}/src/main/resources</directory>
            </resource>
            <resource>
                <directory>src/main/resources</directory>
            </resource>
        </resources>
    </build>

    <profiles>
        <profile>
            <id>dbaas</id>           
            <dependencies>
                <dependency>
                    <groupId>org.apache.spark</groupId>
                    <artifactId>spark-mesos_${scala.binary.version}</artifactId>
                    <version>${spark.version}</version>
                </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-network-yarn_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-yarn_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
                <exclusions>
                    <exclusion>
                        <groupId>org.apache.hadoop</groupId>
                        <artifactId>hadoop-yarn-api</artifactId>
                    </exclusion>
                    <exclusion>
                        <groupId>org.apache.hadoop</groupId>
                        <artifactId>hadoop-yarn-server-web-proxy</artifactId>
                    </exclusion>
                    <exclusion>
                        <groupId>org.apache.hadoop</groupId>
                        <artifactId>hadoop-client</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-streaming_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-streaming-kafka-0-10_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
            </dependency>
            <dependency>
                <groupId>org.apache.spark</groupId>
                <artifactId>spark-network-common_${scala.binary.version}</artifactId>
                <version>${spark.version}</version>
                <exclusions>
                    <exclusion>
                        <groupId>org.scalatest</groupId>
                        <artifactId>scalatest_${scala.binary.version}</artifactId>
                    </exclusion>
                </exclusions>
            </dependency>
            </dependencies>
            <build>
                <plugins>
                    <plugin>
                      <artifactId>maven-jar-plugin</artifactId>
                      <executions>
                        <!-- Jar has to be shaded since the classifier is not recognized by shading -->
                        <execution>
                          <id>shaded-jar</id>
                          <goals>
                            <goal>jar</goal>
                          </goals>
                        </execution>
                      </executions>
                    </plugin>

                    <plugin>
                        <groupId>org.apache.maven.plugins</groupId>
                        <artifactId>maven-shade-plugin</artifactId>
                        <configuration>
                            <artifactSet>
                                <includes>
                                    <include>io.netty:netty-all</include>
                                </includes>
                                <excludes>
                                    <exclude>com.esotericsoftware:kryo-shaded</exclude>
                                </excludes>
                            </artifactSet>
                            <filters>
                                <filter>
                                    <artifact>*:*</artifact>
                                    <excludes>
                                        <exclude>META-INF/*.SF</exclude>
                                        <exclude>META-INF/*.DSA</exclude>
                                        <exclude>META-INF/*.RSA</exclude>
                                    </excludes>
                                </filter>
                            </filters>
                            <relocations>
                                <relocation>
                                    <pattern>io.netty</pattern>
                                    <shadedPattern>org.spark_project.io.netty</shadedPattern>
                                    <includes>
                                        <include>io.netty.**</include>
                                    </includes>
                                </relocation>
                            </relocations>
                        </configuration>
                        <executions>
                            <execution>
                                <phase>package</phase>
                                <goals>
                                    <goal>shade</goal>
                                </goals>
                            </execution>
                        </executions>
                    </plugin>
                </plugins> 
            </build>
        </profile>
    </profiles>
</project>
