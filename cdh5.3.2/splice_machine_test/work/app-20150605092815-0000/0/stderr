15/06/05 09:28:20 INFO executor.CoarseGrainedExecutorBackend: Registered signal handlers for [TERM, HUP, INT]
15/06/05 09:28:22 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
15/06/05 09:28:22 INFO spark.SecurityManager: Changing view acls to: jleach
15/06/05 09:28:22 INFO spark.SecurityManager: Changing modify acls to: jleach
15/06/05 09:28:22 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jleach); users with modify permissions: Set(jleach)
15/06/05 09:28:23 INFO slf4j.Slf4jLogger: Slf4jLogger started
15/06/05 09:28:23 INFO Remoting: Starting remoting
15/06/05 09:28:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://driverPropsFetcher@192.168.0.83:61255]
15/06/05 09:28:23 INFO util.Utils: Successfully started service 'driverPropsFetcher' on port 61255.
15/06/05 09:28:23 INFO spark.SecurityManager: Changing view acls to: jleach
15/06/05 09:28:23 INFO spark.SecurityManager: Changing modify acls to: jleach
15/06/05 09:28:23 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jleach); users with modify permissions: Set(jleach)
15/06/05 09:28:23 INFO remote.RemoteActorRefProvider$RemotingTerminator: Shutting down remote daemon.
15/06/05 09:28:23 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remote daemon shut down; proceeding with flushing remote transports.
15/06/05 09:28:23 INFO slf4j.Slf4jLogger: Slf4jLogger started
15/06/05 09:28:23 INFO Remoting: Starting remoting
15/06/05 09:28:23 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkExecutor@192.168.0.83:61257]
15/06/05 09:28:23 INFO util.Utils: Successfully started service 'sparkExecutor' on port 61257.
15/06/05 09:28:23 INFO remote.RemoteActorRefProvider$RemotingTerminator: Remoting shut down.
15/06/05 09:28:23 INFO executor.CoarseGrainedExecutorBackend: Connecting to driver: akka.tcp://sparkDriver@192.168.0.83:61251/user/CoarseGrainedScheduler
15/06/05 09:28:23 INFO worker.WorkerWatcher: Connecting to worker akka.tcp://sparkWorker@192.168.0.83:61188/user/Worker
15/06/05 09:28:23 INFO worker.WorkerWatcher: Successfully connected to akka.tcp://sparkWorker@192.168.0.83:61188/user/Worker
15/06/05 09:28:23 INFO executor.CoarseGrainedExecutorBackend: Successfully registered with driver
15/06/05 09:28:23 INFO spark.SecurityManager: Changing view acls to: jleach
15/06/05 09:28:23 INFO spark.SecurityManager: Changing modify acls to: jleach
15/06/05 09:28:23 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jleach); users with modify permissions: Set(jleach)
15/06/05 09:28:23 INFO util.AkkaUtils: Connecting to MapOutputTracker: akka.tcp://sparkDriver@192.168.0.83:61251/user/MapOutputTracker
15/06/05 09:28:23 INFO util.AkkaUtils: Connecting to BlockManagerMaster: akka.tcp://sparkDriver@192.168.0.83:61251/user/BlockManagerMaster
15/06/05 09:28:23 INFO storage.DiskBlockManager: Created local directory at /tmp/spark-local-20150605092823-6028
15/06/05 09:28:23 INFO storage.MemoryStore: MemoryStore started with capacity 706.6 MB
15/06/05 09:28:24 INFO netty.NettyBlockTransferService: Server created on 61260
15/06/05 09:28:24 INFO storage.BlockManagerMaster: Trying to register BlockManager
15/06/05 09:28:24 INFO storage.BlockManagerMaster: Registered BlockManager
15/06/05 09:28:24 INFO util.AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@192.168.0.83:61251/user/HeartbeatReceiver
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 0
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 1
15/06/05 09:28:24 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
15/06/05 09:28:24 INFO executor.Executor: Running task 1.0 in stage 0.0 (TID 1)
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 2
15/06/05 09:28:24 INFO executor.Executor: Running task 2.0 in stage 0.0 (TID 2)
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 3
15/06/05 09:28:24 INFO executor.Executor: Running task 3.0 in stage 0.0 (TID 3)
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 4
15/06/05 09:28:24 INFO executor.Executor: Running task 4.0 in stage 0.0 (TID 4)
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 5
15/06/05 09:28:24 INFO executor.Executor: Running task 5.0 in stage 0.0 (TID 5)
15/06/05 09:28:24 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 6
15/06/05 09:28:24 INFO executor.Executor: Running task 6.0 in stage 0.0 (TID 6)
15/06/05 09:28:24 INFO Configuration.deprecation: hadoop.native.lib is deprecated. Instead, use io.native.lib.available
15/06/05 09:28:24 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 1
15/06/05 09:28:24 INFO storage.MemoryStore: ensureFreeSpace(6742) called with curMem=0, maxMem=740960501
15/06/05 09:28:24 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 6.6 KB, free 706.6 MB)
15/06/05 09:28:24 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
15/06/05 09:28:24 INFO broadcast.TorrentBroadcast: Reading broadcast variable 1 took 202 ms
15/06/05 09:28:24 INFO storage.MemoryStore: ensureFreeSpace(14768) called with curMem=6742, maxMem=740960501
15/06/05 09:28:24 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 14.4 KB, free 706.6 MB)
15/06/05 09:28:25 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3d10edc2 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:zookeeper.version=3.4.5-cdh5.3.2--1, built on 02/24/2015 20:43 GMT
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:host.name=192.168.0.83
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.version=1.7.0_71
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.vendor=Oracle Corporation
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.home=/Library/Java/JavaVirtualMachines/jdk1.7.0_71.jdk/Contents/Home/jre
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.class.path=/Users/jleach/.m2/repository/com/splicemachine/splice_machine_adapter_98-cdh5.3.2/1.1.1-SNAPSHOT/splice_machine_adapter_98-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_machine-cdh5.3.2/1.1.1-SNAPSHOT/splice_machine-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_si_adapter_98-cdh5.3.2/1.1.1-SNAPSHOT/splice_si_adapter_98-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_si-cdh5.3.2/1.1.1-SNAPSHOT/splice_si-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_constants-cdh5.3.2/1.1.1-SNAPSHOT/splice_constants-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4.2/concurrentlinkedhashmap-lru-1.4.2.jar:/Users/jleach/.m2/repository/joda-time/joda-time/2.3/joda-time-2.3.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-client/2.5.0-cdh5.3.2/hadoop-client-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-app/2.5.0-cdh5.3.2/hadoop-mapreduce-client-app-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-common/2.5.0-cdh5.3.2/hadoop-mapreduce-client-common-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-yarn-client/2.5.0-cdh5.3.2/hadoop-yarn-client-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/com/sun/jersey/jersey-client/1.9/jersey-client-1.9.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-yarn-server-common/2.5.0-cdh5.3.2/hadoop-yarn-server-common-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.5.0-cdh5.3.2/hadoop-mapreduce-client-shuffle-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-yarn-api/2.5.0-cdh5.3.2/hadoop-yarn-api-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-core/2.5.0-cdh5.3.2/hadoop-mapreduce-client-core-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-yarn-common/2.5.0-cdh5.3.2/hadoop-yarn-common-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.5.0-cdh5.3.2/hadoop-mapreduce-client-jobclient-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-aws/2.5.0-cdh5.3.2/hadoop-aws-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.2.3/jackson-databind-2.2.3.jar:/Users/jleach/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.2.3/jackson-core-2.2.3.jar:/Users/jleach/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.2.3/jackson-annotations-2.2.3.jar:/Users/jleach/.m2/repository/com/amazonaws/aws-java-sdk/1.7.4/aws-java-sdk-1.7.4.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-annotations/2.5.0-cdh5.3.2/hadoop-annotations-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-common/2.5.0-cdh5.3.2/hadoop-common-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/Users/jleach/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/Users/jleach/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/Users/jleach/.m2/repository/commons-codec/commons-codec/1.4/commons-codec-1.4.jar:/Users/jleach/.m2/repository/commons-net/commons-net/3.1/commons-net-3.1.jar:/Users/jleach/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/Users/jleach/.m2/repository/org/mortbay/jetty/jetty/6.1.26.cloudera.4/jetty-6.1.26.cloudera.4.jar:/Users/jleach/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26.cloudera.4/jetty-util-6.1.26.cloudera.4.jar:/Users/jleach/.m2/repository/javax/servlet/jsp/jsp-api/2.1/jsp-api-2.1.jar:/Users/jleach/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/Users/jleach/.m2/repository/net/java/dev/jets3t/jets3t/0.9.0/jets3t-0.9.0.jar:/Users/jleach/.m2/repository/com/jamesmurty/utils/java-xmlbuilder/0.4/java-xmlbuilder-0.4.jar:/Users/jleach/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/Users/jleach/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/Users/jleach/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/Users/jleach/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/Users/jleach/.m2/repository/org/slf4j/slf4j-api/1.7.5/slf4j-api-1.7.5.jar:/Users/jleach/.m2/repository/org/slf4j/slf4j-log4j12/1.7.5/slf4j-log4j12-1.7.5.jar:/Users/jleach/.m2/repository/org/apache/avro/avro/1.7.6-cdh5.3.2/avro-1.7.6-cdh5.3.2.jar:/Users/jleach/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar:/Users/jleach/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-auth/2.5.0-cdh5.3.2/hadoop-auth-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/Users/jleach/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/Users/jleach/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/Users/jleach/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/Users/jleach/.m2/repository/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar:/Users/jleach/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/Users/jleach/.m2/repository/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar:/Users/jleach/.m2/repository/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar:/Users/jleach/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/Users/jleach/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.0-cdh5.3.2/hadoop-hdfs-2.5.0-cdh5.3.2.jar:/Users/jleach/.m2/repository/commons-daemon/commons-daemon/1.0.13/commons-daemon-1.0.13.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-client/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-client-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-common/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-common-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/cloudera/htrace/htrace-core/2.04/htrace-core-2.04.jar:/Users/jleach/.m2/repository/com/github/stephenc/findbugs/findbugs-annotations/1.3.9-1/findbugs-annotations-1.3.9-1.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-common/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-common-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT-tests.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-core/2.5.0-mr1-cdh5.3.2/hadoop-core-2.5.0-mr1-cdh5.3.2.jar:/Users/jleach/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/Users/jleach/.m2/repository/org/eclipse/jdt/core/3.1.1/core-3.1.1.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-protocol/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-protocol-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-server/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-server-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-prefix-tree/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-prefix-tree-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-hadoop-compat/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-hadoop-compat-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-hadoop2-compat-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/yammer/metrics/metrics-core/2.1.2/metrics-core-2.1.2.jar:/Users/jleach/.m2/repository/org/apache/commons/commons-math/2.1/commons-math-2.1.jar:/Users/jleach/.m2/repository/org/mortbay/jetty/jetty-sslengine/6.1.26.cloudera.4/jetty-sslengine-6.1.26.cloudera.4.jar:/Users/jleach/.m2/repository/org/mortbay/jetty/jsp-2.1/6.1.14/jsp-2.1-6.1.14.jar:/Users/jleach/.m2/repository/org/mortbay/jetty/jsp-api-2.1/6.1.14/jsp-api-2.1-6.1.14.jar:/Users/jleach/.m2/repository/org/jamon/jamon-runtime/2.3.1/jamon-runtime-2.3.1.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.5.0-cdh5.3.2/hadoop-hdfs-2.5.0-cdh5.3.2-tests.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-testing-util/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-testing-util-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-server/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-server-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT-tests.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-hadoop-compat/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-hadoop-compat-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT-tests.jar:/Users/jleach/.m2/repository/org/apache/hbase/hbase-hadoop2-compat/0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT/hbase-hadoop2-compat-0.98.6-cdh5.3.2-splice1.0.2-SNAPSHOT-tests.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-minicluster/2.5.0-mr1-cdh5.3.2/hadoop-minicluster-2.5.0-mr1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-test/2.5.0-mr1-cdh5.3.2/hadoop-test-2.5.0-mr1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/ftpserver/ftplet-api/1.0.0/ftplet-api-1.0.0.jar:/Users/jleach/.m2/repository/org/apache/mina/mina-core/2.0.0-M5/mina-core-2.0.0-M5.jar:/Users/jleach/.m2/repository/org/apache/ftpserver/ftpserver-core/1.0.0/ftpserver-core-1.0.0.jar:/Users/jleach/.m2/repository/org/apache/ftpserver/ftpserver-deprecated/1.0.0-M2/ftpserver-deprecated-1.0.0-M2.jar:/Users/jleach/.m2/repository/org/apache/hadoop/hadoop-common/2.5.0-cdh5.3.2/hadoop-common-2.5.0-cdh5.3.2-tests.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-beeline/0.13.1-cdh5.3.2/hive-beeline-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-metastore/0.13.1-cdh5.3.2/hive-metastore-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/com/jolbox/bonecp/0.8.0.RELEASE/bonecp-0.8.0.RELEASE.jar:/Users/jleach/.m2/repository/org/apache/derby/derby/10.10.1.1/derby-10.10.1.1.jar:/Users/jleach/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.6/datanucleus-api-jdo-3.2.6.jar:/Users/jleach/.m2/repository/org/datanucleus/datanucleus-core/3.2.10/datanucleus-core-3.2.10.jar:/Users/jleach/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.9/datanucleus-rdbms-3.2.9.jar:/Users/jleach/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/Users/jleach/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/Users/jleach/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/Users/jleach/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/Users/jleach/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/Users/jleach/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/Users/jleach/.m2/repository/org/apache/thrift/libthrift/0.9.0-cdh5-2/libthrift-0.9.0-cdh5-2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-cli/0.13.1-cdh5.3.2/hive-cli-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-serde/0.13.1-cdh5.3.2/hive-serde-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/com/sun/jersey/jersey-servlet/1.14/jersey-servlet-1.14.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-exec/0.13.1-cdh5.3.2/hive-exec-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-ant/0.13.1-cdh5.3.2/hive-ant-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/velocity/velocity/1.5/velocity-1.5.jar:/Users/jleach/.m2/repository/oro/oro/2.0.8/oro-2.0.8.jar:/Users/jleach/.m2/repository/org/apache/commons/commons-lang3/3.1/commons-lang3-3.1.jar:/Users/jleach/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/Users/jleach/.m2/repository/org/apache/ant/ant/1.9.1/ant-1.9.1.jar:/Users/jleach/.m2/repository/org/apache/ant/ant-launcher/1.9.1/ant-launcher-1.9.1.jar:/Users/jleach/.m2/repository/org/codehaus/groovy/groovy-all/2.1.6/groovy-all-2.1.6.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-common/0.13.1-cdh5.3.2/hive-common-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-contrib/0.13.1-cdh5.3.2/hive-contrib-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-hbase-handler/0.13.1-cdh5.3.2/hive-hbase-handler-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-hwi/0.13.1-cdh5.3.2/hive-hwi-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-jdbc/0.13.1-cdh5.3.2/hive-jdbc-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/Users/jleach/.m2/repository/org/apache/httpcomponents/httpcore/4.2.5/httpcore-4.2.5.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-service/0.13.1-cdh5.3.2/hive-service-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/net/sf/jpam/jpam/1.1/jpam-1.1.jar:/Users/jleach/.m2/repository/org/eclipse/jetty/aggregate/jetty-all/7.6.0.v20120127/jetty-all-7.6.0.v20120127.jar:/Users/jleach/.m2/repository/org/apache/geronimo/specs/geronimo-jta_1.1_spec/1.1.1/geronimo-jta_1.1_spec-1.1.1.jar:/Users/jleach/.m2/repository/javax/mail/mail/1.4.1/mail-1.4.1.jar:/Users/jleach/.m2/repository/org/apache/geronimo/specs/geronimo-jaspic_1.0_spec/1.0/geronimo-jaspic_1.0_spec-1.0.jar:/Users/jleach/.m2/repository/org/apache/geronimo/specs/geronimo-annotation_1.0_spec/1.1.1/geronimo-annotation_1.0_spec-1.1.1.jar:/Users/jleach/.m2/repository/asm/asm-commons/3.1/asm-commons-3.1.jar:/Users/jleach/.m2/repository/asm/asm-tree/3.1/asm-tree-3.1.jar:/Users/jleach/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/Users/jleach/.m2/repository/org/apache/hive/hive-shims/0.13.1-cdh5.3.2/hive-shims-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/shims/hive-shims-common/0.13.1-cdh5.3.2/hive-shims-common-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/shims/hive-shims-common-secure/0.13.1-cdh5.3.2/hive-shims-common-secure-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/shims/hive-shims-0.23/0.13.1-cdh5.3.2/hive-shims-0.23-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/hive/shims/hive-shims-scheduler/0.13.1-cdh5.3.2/hive-shims-scheduler-0.13.1-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5-cdh5.3.2/zookeeper-3.4.5-cdh5.3.2.jar:/Users/jleach/.m2/repository/org/apache/spark/spark-assembly-hadoop2.5.0-cdh5.3.2/1.2.0/spark-assembly-hadoop2.5.0-cdh5.3.2-1.2.0.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_protocol-cdh5.3.2/1.1.1-SNAPSHOT/splice_protocol-cdh5.3.2-1.1.1-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/asynchbase/1.5.5/asynchbase-1.5.5.jar:/Users/jleach/.m2/repository/com/stumbleupon/async/1.4.0/async-1.4.0.jar:/Users/jleach/.m2/repository/org/scala-lang/scala-library/2.10.4/scala-library-2.10.4.jar:/Users/jleach/.m2/repository/com/splicemachine/splice_machine_adapter_98-cdh5.3.2/1.1.1-SNAPSHOT/splice_machine_adapter_98-cdh5.3.2-1.1.1-SNAPSHOT-tests.jar:/Users/jleach/.m2/repository/org/splicetest/sqlj/sqlj-it-procs/1.0.2-SNAPSHOT/sqlj-it-procs-1.0.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/Users/jleach/.m2/repository/com/carrotsearch/hppc/0.5.2/hppc-0.5.2.jar:/Users/jleach/.m2/repository/com/carrotsearch/java-sizeof/0.0.4/java-sizeof-0.0.4.jar:/Users/jleach/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/Users/jleach/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/Users/jleach/.m2/repository/org/ow2/asm/asm/4.0/asm-4.0.jar:/Users/jleach/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/Users/jleach/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/Users/jleach/.m2/repository/com/github/stephenc/high-scale-lib/high-scale-lib/1.1.1/high-scale-lib-1.1.1.jar:/Users/jleach/.m2/repository/com/google/code/findbugs/jsr305/1.3.9/jsr305-1.3.9.jar:/Users/jleach/.m2/repository/com/google/code/gson/gson/2.2.2/gson-2.2.2.jar:/Users/jleach/.m2/repository/com/google/guava/guava/11.0.2/guava-11.0.2.jar:/Users/jleach/.m2/repository/com/lmax/disruptor/3.2.1/disruptor-3.2.1.jar:/Users/jleach/.m2/repository/com/splicemachine/utilities/1.1.2-SNAPSHOT/utilities-1.1.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/stats/1.0.0-SNAPSHOT/stats-1.0.0-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/splice-web/1.1.0-SNAPSHOT/splice-web-1.1.0-SNAPSHOT.tar.gz:/Users/jleach/.m2/repository/com/sun/jersey/jersey-core/1.8/jersey-core-1.8.jar:/Users/jleach/.m2/repository/com/sun/jersey/jersey-json/1.8/jersey-json-1.8.jar:/Users/jleach/.m2/repository/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar:/Users/jleach/.m2/repository/stax/stax-api/1.0.1/stax-api-1.0.1.jar:/Users/jleach/.m2/repository/com/sun/xml/bind/jaxb-impl/2.2.3-1/jaxb-impl-2.2.3-1.jar:/Users/jleach/.m2/repository/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar:/Users/jleach/.m2/repository/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar:/Users/jleach/.m2/repository/javax/activation/activation/1.1/activation-1.1.jar:/Users/jleach/.m2/repository/org/codehaus/jackson/jackson-jaxrs/1.7.1/jackson-jaxrs-1.7.1.jar:/Users/jleach/.m2/repository/org/codehaus/jackson/jackson-xc/1.7.1/jackson-xc-1.7.1.jar:/Users/jleach/.m2/repository/com/sun/jersey/jersey-server/1.8/jersey-server-1.8.jar:/Users/jleach/.m2/repository/asm/asm/3.1/asm-3.1.jar:/Users/jleach/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/Users/jleach/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/Users/jleach/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/Users/jleach/.m2/repository/commons-dbutils/commons-dbutils/1.5/commons-dbutils-1.5.jar:/Users/jleach/.m2/repository/commons-io/commons-io/2.1/commons-io-2.1.jar:/Users/jleach/.m2/repository/commons-lang/commons-lang/2.5/commons-lang-2.5.jar:/Users/jleach/.m2/repository/commons-logging/commons-logging/1.1.1/commons-logging-1.1.1.jar:/Users/jleach/.m2/repository/de/javakaffee/kryo-serializers/0.26/kryo-serializers-0.26.jar:/Users/jleach/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/Users/jleach/.m2/repository/net/sf/ehcache/ehcache-core/2.6.6/ehcache-core-2.6.6.jar:/Users/jleach/.m2/repository/net/sf/opencsv/opencsv/2.3/opencsv-2.3.jar:/Users/jleach/.m2/repository/net/sf/supercsv/super-csv/2.3.2-SNAPSHOT-splice/super-csv-2.3.2-SNAPSHOT-splice.jar:/Users/jleach/.m2/repository/com/splicemachine/db/1.1.1.2-SNAPSHOT/db-1.1.1.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/com/splicemachine/dbclient/1.1.1.2-SNAPSHOT/dbclient-1.1.1.2-SNAPSHOT.jar:/Users/jleach/.m2/repository/org/apache/lucene/lucene-core/4.3.1/lucene-core-4.3.1.jar:/Users/jleach/.m2/repository/org/apache/mrunit/mrunit/1.0.0/mrunit-1.0.0-hadoop2.jar:/Users/jleach/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.1/uncommons-maths-1.2.1.jar:/Users/jleach/.m2/repository/org/uncommons/watchmaker/watchmaker-framework/0.7.1/watchmaker-framework-0.7.1.jar:/Users/jleach/.m2/repository/junit/junit/4.11/junit-4.11.jar:/Users/jleach/.m2/repository/org/hamcrest/hamcrest-core/1.3/hamcrest-core-1.3.jar:/Users/jleach/.m2/repository/org/mockito/mockito-all/1.9.5/mockito-all-1.9.5.jar:/Users/jleach/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/Users/jleach/Documents/workspace/spliceengine/cdh5.3.2/splice_machine_test/target/classes
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.library.path=:/Users/jleach/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.io.tmpdir=/var/folders/01/td1fd0hx6z72c6g58vqc1tnr0000gp/T/
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:java.compiler=<NA>
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:os.name=Mac OS X
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:os.arch=x86_64
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:os.version=10.10.3
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:user.name=jleach
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:user.home=/Users/jleach
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Client environment:user.dir=/Users/jleach/Documents/workspace/spliceengine/cdh5.3.2/splice_machine_test/work/app-20150605092815-0000/0
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x3d10edc2, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90011, negotiated timeout = 60000
15/06/05 09:28:25 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x2d1c3d6b connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:25 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x2d1c3d6b, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:25 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:25 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90012, negotiated timeout = 60000
15/06/05 09:28:25 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:25 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:26 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x10f679f2 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:26 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x10f679f2, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:26 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:26 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:26 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:26 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:26 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:26 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:26 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90013, negotiated timeout = 60000
15/06/05 09:28:27 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3e0d70f4 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:27 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x3e0d70f4, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:27 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:27 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:27 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:27 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:27 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:27 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:27 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90014, negotiated timeout = 60000
15/06/05 09:28:28 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x53d00a66 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:28 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x53d00a66, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:28 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:28 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:28 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:28 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:28 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:28 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:28 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90015, negotiated timeout = 60000
15/06/05 09:28:29 INFO temp.TempTable: Temp Table initial bucket count: 16
15/06/05 09:28:29 INFO zookeeper.RecoverableZooKeeper: Process identifier=spliceconnection connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:29 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=spliceconnection, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90016, negotiated timeout = 60000
15/06/05 09:28:29 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3c958935 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:29 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x3c958935, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:29 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:29 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:29 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:29 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90017, negotiated timeout = 60000
15/06/05 09:28:30 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x3b7d5d83 connecting to ZooKeeper ensemble=localhost:2181
15/06/05 09:28:30 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=localhost:2181 sessionTimeout=90000 watcher=hconnection-0x3b7d5d83, quorum=localhost:2181, baseZNode=/hbase
15/06/05 09:28:30 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:30 WARN zookeeper.ClientCnxn: Session 0x0 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:28:31 WARN zookeeper.RecoverableZooKeeper: Possibly transient ZooKeeper, quorum=localhost:2181, exception=org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hbase/hbaseid
15/06/05 09:28:31 INFO util.RetryCounter: Sleeping 1000ms before retry #0...
15/06/05 09:28:31 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:31 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:31 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90018, negotiated timeout = 60000
15/06/05 09:28:32 ERROR utils.PipelineConstants: No Native Snappy Installed: Splice Machine's Write Pipeline will not compress data over the wire.
15/06/05 09:28:32 INFO hbase.SpliceDriver: Booting the SpliceDriver
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /ddl already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /ddl/ongoingChanges already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /ddl/activeServers already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /spliceTasks already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /spliceJobs already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /conglomerates already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /conglomerates/__CONGLOM_SEQUENCE already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /derbyPropertyPath already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /conglomerates already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /transactions already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /transactions/maxReservedTimestamp already exists and this is not a retry
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Node /transactions/minimum already exists and this is not a retry
15/06/05 09:28:32 INFO db.SpliceDatabase: Booting the Splice Machine database
15/06/05 09:28:32 INFO txn.SpliceTimestampSource: Creating the TimestampClient...
15/06/05 09:28:32 INFO timestamp.TimestampClient: TimestampClient on region server successfully registered with JMX
15/06/05 09:28:32 INFO timestamp.TimestampClient: Attempting to connect to server (host 192.168.0.83, port 60012)
15/06/05 09:28:32 INFO timestamp.TimestampClient: Successfully connected to server
15/06/05 09:28:32 INFO catalog.SpliceDataDictionary: Splice Software Version = 1.1.1
15/06/05 09:28:32 INFO catalog.SpliceDataDictionary: Splice Catalog Version = 1.1.1
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4(\xDF\xE4\x00\x83,\xE47c#\x00\x82
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4\x0B\xCCG\x00\x82,\xE4\x1AP\xC3\x00\x82
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4E\xEAB\x00\x84,\xE4Tr\x80\x00\x83
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE47c#\x00\x82,\xE4E\xEAB\x00\x84
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4\x1AP\xC3\x00\x82,\xE4(\xDF\xE4\x00\x83
15/06/05 09:28:32 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 0
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,\xE4\x0B\xCCG\x00\x82
15/06/05 09:28:32 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4Tr\x80\x00\x83,
15/06/05 09:28:32 INFO storage.MemoryStore: ensureFreeSpace(22528) called with curMem=21510, maxMem=740960501
15/06/05 09:28:32 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 22.0 KB, free 706.6 MB)
15/06/05 09:28:32 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
15/06/05 09:28:32 INFO broadcast.TorrentBroadcast: Reading broadcast variable 0 took 9 ms
15/06/05 09:28:32 INFO hbase.SpliceDriver: Splice Engine is Running, Enabling Services
15/06/05 09:28:32 INFO hbase.SpliceDriver: Splice Machine Release = 1.1.1-SNAPSHOT
15/06/05 09:28:32 INFO hbase.SpliceDriver: Splice Machine Version Hash = d842c0c520
15/06/05 09:28:32 INFO hbase.SpliceDriver: Splice Machine Build Time = 2015-06-05 14:23 +0000
15/06/05 09:28:32 INFO hbase.SpliceDriver: Splice Machine URL = http://www.splicemachine.com
15/06/05 09:28:32 INFO hbase.SpliceDriver: Services successfully started, enabling JDBC connections...
15/06/05 09:28:32 INFO hbase.SpliceDriver: Ready to accept JDBC connections on 0.0.0.0:1527
15/06/05 09:28:32 INFO storage.MemoryStore: ensureFreeSpace(389795) called with curMem=44038, maxMem=740960501
15/06/05 09:28:32 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 380.7 KB, free 706.2 MB)
15/06/05 09:28:32 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1ca385f8 connecting to ZooKeeper ensemble=127.0.0.1:2181
15/06/05 09:28:32 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=hconnection-0x1ca385f8, quorum=127.0.0.1:2181, baseZNode=/hbase
15/06/05 09:28:32 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:32 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:32 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c90019, negotiated timeout = 60000
15/06/05 09:28:33 INFO hfile.CacheConfig: Allocating LruBlockCache with maximum size 1.9 G
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO util.ChecksumType: Checksum using org.apache.hadoop.util.PureJavaCrc32
15/06/05 09:28:33 INFO util.ChecksumType: Checksum can use org.apache.hadoop.util.PureJavaCrc32C
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:33 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:35 INFO regionserver.HStore: Closed V
15/06/05 09:28:35 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:35 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:36 INFO executor.Executor: Finished task 6.0 in stage 0.0 (TID 6). 2014 bytes result sent to driver
15/06/05 09:28:36 INFO regionserver.HStore: Closed V
15/06/05 09:28:36 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:36 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:37 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO regionserver.HStore: Closed V
15/06/05 09:28:38 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:38 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:38 INFO regionserver.HStore: Closed V
15/06/05 09:28:38 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:38 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:38 INFO executor.Executor: Finished task 2.0 in stage 0.0 (TID 2). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO regionserver.HStore: Closed V
15/06/05 09:28:38 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:38 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:38 INFO executor.Executor: Finished task 1.0 in stage 0.0 (TID 1). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO regionserver.HStore: Closed V
15/06/05 09:28:38 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:38 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:38 INFO client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
15/06/05 09:28:38 INFO client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x14dc41d88c90019
15/06/05 09:28:38 INFO executor.Executor: Finished task 4.0 in stage 0.0 (TID 4). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO zookeeper.ZooKeeper: Session: 0x14dc41d88c90019 closed
15/06/05 09:28:38 INFO zookeeper.ClientCnxn: EventThread shut down
15/06/05 09:28:38 INFO executor.Executor: Finished task 5.0 in stage 0.0 (TID 5). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO regionserver.HStore: Closed V
15/06/05 09:28:38 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:38 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:38 INFO executor.Executor: Finished task 3.0 in stage 0.0 (TID 3). 2014 bytes result sent to driver
15/06/05 09:28:38 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 7
15/06/05 09:28:38 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 7)
15/06/05 09:28:38 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 2
15/06/05 09:28:38 INFO storage.MemoryStore: ensureFreeSpace(5971) called with curMem=433833, maxMem=740960501
15/06/05 09:28:38 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 5.8 KB, free 706.2 MB)
15/06/05 09:28:38 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/06/05 09:28:38 INFO broadcast.TorrentBroadcast: Reading broadcast variable 2 took 9 ms
15/06/05 09:28:38 INFO storage.MemoryStore: ensureFreeSpace(12160) called with curMem=439804, maxMem=740960501
15/06/05 09:28:38 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 11.9 KB, free 706.2 MB)
15/06/05 09:28:38 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 7). 718 bytes result sent to driver
15/06/05 09:28:42 INFO storage.BlockManager: Removing broadcast 1
15/06/05 09:28:42 INFO storage.BlockManager: Removing block broadcast_1_piece0
15/06/05 09:28:42 INFO storage.MemoryStore: Block broadcast_1_piece0 of size 6742 dropped from memory (free 740515279)
15/06/05 09:28:42 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
15/06/05 09:28:42 INFO storage.BlockManager: Removing block broadcast_1
15/06/05 09:28:42 INFO storage.MemoryStore: Block broadcast_1 of size 14768 dropped from memory (free 740530047)
15/06/05 09:28:42 INFO storage.BlockManager: Removing broadcast 2
15/06/05 09:28:42 INFO storage.BlockManager: Removing block broadcast_2
15/06/05 09:28:42 INFO storage.MemoryStore: Block broadcast_2 of size 12160 dropped from memory (free 740542207)
15/06/05 09:28:42 INFO storage.BlockManager: Removing block broadcast_2_piece0
15/06/05 09:28:42 INFO storage.MemoryStore: Block broadcast_2_piece0 of size 5971 dropped from memory (free 740548178)
15/06/05 09:28:42 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 8
15/06/05 09:28:43 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 8)
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 9
15/06/05 09:28:43 INFO executor.Executor: Running task 1.0 in stage 2.0 (TID 9)
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 10
15/06/05 09:28:43 INFO executor.Executor: Running task 2.0 in stage 2.0 (TID 10)
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 11
15/06/05 09:28:43 INFO executor.Executor: Running task 3.0 in stage 2.0 (TID 11)
15/06/05 09:28:43 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 4
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 12
15/06/05 09:28:43 INFO executor.Executor: Running task 4.0 in stage 2.0 (TID 12)
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 13
15/06/05 09:28:43 INFO executor.Executor: Running task 5.0 in stage 2.0 (TID 13)
15/06/05 09:28:43 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 14
15/06/05 09:28:43 INFO executor.Executor: Running task 6.0 in stage 2.0 (TID 14)
15/06/05 09:28:43 INFO storage.MemoryStore: ensureFreeSpace(6753) called with curMem=412323, maxMem=740960501
15/06/05 09:28:43 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 6.6 KB, free 706.2 MB)
15/06/05 09:28:43 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
15/06/05 09:28:43 INFO broadcast.TorrentBroadcast: Reading broadcast variable 4 took 14 ms
15/06/05 09:28:43 INFO storage.MemoryStore: ensureFreeSpace(14768) called with curMem=419076, maxMem=740960501
15/06/05 09:28:43 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 14.4 KB, free 706.2 MB)
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4Tr\x80\x00\x83,
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,\xE4\x0B\xCCG\x00\x82
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4\x1AP\xC3\x00\x82,\xE4(\xDF\xE4\x00\x83
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4(\xDF\xE4\x00\x83,\xE47c#\x00\x82
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE47c#\x00\x82,\xE4E\xEAB\x00\x84
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4\x0B\xCCG\x00\x82,\xE4\x1AP\xC3\x00\x82
15/06/05 09:28:43 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:\xE4E\xEAB\x00\x84,\xE4Tr\x80\x00\x83
15/06/05 09:28:43 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 3
15/06/05 09:28:43 INFO storage.MemoryStore: ensureFreeSpace(22527) called with curMem=433844, maxMem=740960501
15/06/05 09:28:43 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 22.0 KB, free 706.2 MB)
15/06/05 09:28:43 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/06/05 09:28:43 INFO broadcast.TorrentBroadcast: Reading broadcast variable 3 took 8 ms
15/06/05 09:28:43 INFO storage.MemoryStore: ensureFreeSpace(389795) called with curMem=456371, maxMem=740960501
15/06/05 09:28:43 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 380.7 KB, free 705.8 MB)
15/06/05 09:28:43 INFO zookeeper.RecoverableZooKeeper: Process identifier=hconnection-0x1d3afee7 connecting to ZooKeeper ensemble=127.0.0.1:2181
15/06/05 09:28:43 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=127.0.0.1:2181 sessionTimeout=90000 watcher=hconnection-0x1d3afee7, quorum=127.0.0.1:2181, baseZNode=/hbase
15/06/05 09:28:43 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:28:43 INFO zookeeper.ClientCnxn: Socket connection established to localhost/127.0.0.1:2181, initiating session
15/06/05 09:28:43 INFO zookeeper.ClientCnxn: Session establishment complete on server localhost/127.0.0.1:2181, sessionid = 0x14dc41d88c9001a, negotiated timeout = 60000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:43 INFO compactions.CompactionConfiguration: size [16777216, 260046848); files [5, 10); ratio 1.250000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:28:43 INFO regionserver.HRegion: Onlined cc29f7fe9f9fd932551fa393db6be396; next sequenceid=1216
15/06/05 09:28:44 INFO regionserver.HStore: Closed V
15/06/05 09:28:44 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:44 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:44 INFO executor.Executor: Finished task 6.0 in stage 2.0 (TID 14). 1851 bytes result sent to driver
15/06/05 09:28:45 INFO regionserver.HStore: Closed V
15/06/05 09:28:45 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:45 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:45 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 8). 2014 bytes result sent to driver
15/06/05 09:28:45 INFO regionserver.HStore: Closed V
15/06/05 09:28:45 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:45 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:45 INFO regionserver.HStore: Closed V
15/06/05 09:28:45 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:45 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:45 INFO executor.Executor: Finished task 4.0 in stage 2.0 (TID 12). 2014 bytes result sent to driver
15/06/05 09:28:45 INFO executor.Executor: Finished task 3.0 in stage 2.0 (TID 11). 2014 bytes result sent to driver
15/06/05 09:28:46 INFO regionserver.HStore: Closed V
15/06/05 09:28:46 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:46 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:46 INFO regionserver.HStore: Closed V
15/06/05 09:28:46 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:46 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:46 INFO client.HConnectionManager$HConnectionImplementation: Closing master protocol: MasterService
15/06/05 09:28:46 INFO client.HConnectionManager$HConnectionImplementation: Closing zookeeper sessionid=0x14dc41d88c9001a
15/06/05 09:28:46 INFO executor.Executor: Finished task 1.0 in stage 2.0 (TID 9). 2014 bytes result sent to driver
15/06/05 09:28:46 INFO executor.Executor: Finished task 2.0 in stage 2.0 (TID 10). 2014 bytes result sent to driver
15/06/05 09:28:46 INFO zookeeper.ZooKeeper: Session: 0x14dc41d88c9001a closed
15/06/05 09:28:46 INFO zookeeper.ClientCnxn: EventThread shut down
15/06/05 09:28:46 INFO regionserver.HStore: Closed V
15/06/05 09:28:46 INFO regionserver.HRegion: Closed 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396.
15/06/05 09:28:46 WARN regionserver.HRegion: Region 1360,,1433432703382.cc29f7fe9f9fd932551fa393db6be396. already closed
15/06/05 09:28:46 INFO executor.Executor: Finished task 5.0 in stage 2.0 (TID 13). 2014 bytes result sent to driver
15/06/05 09:28:46 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 15
15/06/05 09:28:46 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 15)
15/06/05 09:28:46 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 5
15/06/05 09:28:46 INFO storage.MemoryStore: ensureFreeSpace(5966) called with curMem=846166, maxMem=740960501
15/06/05 09:28:46 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 5.8 KB, free 705.8 MB)
15/06/05 09:28:46 INFO storage.BlockManagerMaster: Updated info of block broadcast_5_piece0
15/06/05 09:28:46 INFO broadcast.TorrentBroadcast: Reading broadcast variable 5 took 9 ms
15/06/05 09:28:46 INFO storage.MemoryStore: ensureFreeSpace(12160) called with curMem=852132, maxMem=740960501
15/06/05 09:28:46 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 11.9 KB, free 705.8 MB)
15/06/05 09:28:46 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 15). 718 bytes result sent to driver
15/06/05 09:29:16 INFO storage.BlockManager: Removing broadcast 5
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_5_piece0
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_5_piece0 of size 5966 dropped from memory (free 740102175)
15/06/05 09:29:16 INFO storage.BlockManagerMaster: Updated info of block broadcast_5_piece0
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_5
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_5 of size 12160 dropped from memory (free 740114335)
15/06/05 09:29:16 INFO storage.BlockManager: Removing broadcast 3
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_3_piece0
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_3_piece0 of size 22527 dropped from memory (free 740136862)
15/06/05 09:29:16 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_3
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_3 of size 389795 dropped from memory (free 740526657)
15/06/05 09:29:16 INFO storage.BlockManager: Removing broadcast 4
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_4
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_4 of size 14768 dropped from memory (free 740541425)
15/06/05 09:29:16 INFO storage.BlockManager: Removing block broadcast_4_piece0
15/06/05 09:29:16 INFO storage.MemoryStore: Block broadcast_4_piece0 of size 6753 dropped from memory (free 740548178)
15/06/05 09:29:16 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
15/06/05 09:30:59 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 16
15/06/05 09:30:59 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 16)
15/06/05 09:30:59 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 17
15/06/05 09:30:59 INFO executor.Executor: Running task 1.0 in stage 4.0 (TID 17)
15/06/05 09:30:59 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 18
15/06/05 09:30:59 INFO executor.Executor: Running task 2.0 in stage 4.0 (TID 18)
15/06/05 09:30:59 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 19
15/06/05 09:30:59 INFO executor.Executor: Running task 3.0 in stage 4.0 (TID 19)
15/06/05 09:30:59 INFO broadcast.TorrentBroadcast: Started reading broadcast variable 6
15/06/05 09:30:59 INFO storage.MemoryStore: ensureFreeSpace(14158) called with curMem=412323, maxMem=740960501
15/06/05 09:30:59 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 13.8 KB, free 706.2 MB)
15/06/05 09:30:59 INFO storage.BlockManagerMaster: Updated info of block broadcast_6_piece0
15/06/05 09:30:59 INFO broadcast.TorrentBroadcast: Reading broadcast variable 6 took 9 ms
15/06/05 09:30:59 INFO storage.MemoryStore: ensureFreeSpace(63112) called with curMem=426481, maxMem=740960501
15/06/05 09:30:59 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 61.6 KB, free 706.2 MB)
15/06/05 09:31:00 WARN spark.SpliceSpark: Initializing Spark with:
 master local[8]
 home null
 jars 
 environment 
15/06/05 09:31:00 INFO spark.SparkContext: Spark configuration:
driver.source.splice-machine.class=com.splicemachine.derby.stream.spark.SpliceMachineSource
executor.source.splice-machine.class=com.splicemachine.derby.stream.spark.SpliceMachineSource
spark.app.name=SpliceMachine
spark.cores.max=8
spark.driver.port=0
spark.executor.extraClassPath=
spark.executor.extraJavaOptions=
spark.executor.extraLibraryPath=
spark.executor.memory=8G
spark.io.compression.codec=lz4
spark.io.compression.lz4.block.size=3276800
spark.kryo.referenceTracking=false
spark.kryo.registrator=com.splicemachine.derby.impl.spark.SpliceSparkKryoRegistrator
spark.kryoserializer.buffer.max.mb=512
spark.kryoserializer.buffer.mb=512
spark.locality.wait=600000
spark.logConf=true
spark.master=local[8]
spark.scheduler.mode=FAIR
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.shuffle.compress=false
spark.shuffle.file.buffer.kb=128
spark.shuffle.memoryFraction=0.5
spark.storage.memoryFraction=0.1
15/06/05 09:31:00 INFO spark.SecurityManager: Changing view acls to: jleach
15/06/05 09:31:00 INFO spark.SecurityManager: Changing modify acls to: jleach
15/06/05 09:31:00 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jleach); users with modify permissions: Set(jleach)
15/06/05 09:31:00 INFO slf4j.Slf4jLogger: Slf4jLogger started
15/06/05 09:31:00 INFO Remoting: Starting remoting
15/06/05 09:31:00 INFO Remoting: Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.0.83:61323]
15/06/05 09:31:00 INFO util.Utils: Successfully started service 'sparkDriver' on port 61323.
15/06/05 09:31:00 INFO spark.SparkEnv: Registering MapOutputTracker
15/06/05 09:31:00 INFO spark.SparkEnv: Registering BlockManagerMaster
15/06/05 09:31:00 INFO storage.DiskBlockManager: Created local directory at /var/folders/01/td1fd0hx6z72c6g58vqc1tnr0000gp/T/spark-local-20150605093100-ec34
15/06/05 09:31:00 INFO storage.MemoryStore: MemoryStore started with capacity 707.9 MB
15/06/05 09:31:00 INFO spark.HttpFileServer: HTTP File server directory is /var/folders/01/td1fd0hx6z72c6g58vqc1tnr0000gp/T/spark-c0896206-2625-4e42-a951-237a8d9af629
15/06/05 09:31:00 INFO spark.HttpServer: Starting HTTP Server
15/06/05 09:31:00 INFO server.Server: jetty-7.6.0.v20120127
15/06/05 09:31:00 INFO server.AbstractConnector: Started SocketConnector@0.0.0.0:61324
15/06/05 09:31:00 INFO util.Utils: Successfully started service 'HTTP file server' on port 61324.
15/06/05 09:31:03 INFO server.Server: jetty-7.6.0.v20120127
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/jobs,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/jobs/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/jobs/job,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/jobs/job/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/stage,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/stage/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/pool,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/pool/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/storage,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/storage/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/storage/rdd,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/environment,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/environment/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/executors,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/executors/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/executors/threadDump,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/static,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/,null}
15/06/05 09:31:03 INFO handler.ContextHandler: started o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
15/06/05 09:31:03 INFO server.AbstractConnector: Started SelectChannelConnector@0.0.0.0:4040
15/06/05 09:31:03 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.
15/06/05 09:31:03 INFO ui.SparkUI: Started SparkUI at http://192.168.0.83:4040
15/06/05 09:31:03 INFO scheduler.FairSchedulableBuilder: Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
15/06/05 09:31:03 INFO util.AkkaUtils: Connecting to HeartbeatReceiver: akka.tcp://sparkDriver@192.168.0.83:61323/user/HeartbeatReceiver
15/06/05 09:31:03 INFO netty.NettyBlockTransferService: Server created on 61325
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Trying to register BlockManager
15/06/05 09:31:03 INFO storage.BlockManagerMasterActor: Registering block manager localhost:61325 with 707.9 MB RAM, BlockManagerId(<driver>, localhost, 61325)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Registered BlockManager
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293704) called with curMem=0, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 286.8 KB, free 707.7 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293704) called with curMem=293704, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 286.8 KB, free 707.4 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293704) called with curMem=587408, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 286.8 KB, free 707.1 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293704) called with curMem=881112, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 286.8 KB, free 706.8 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24404) called with curMem=1174816, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 23.8 KB, free 706.8 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24404) called with curMem=1199220, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.8 KB, free 706.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on localhost:61325 (size: 23.8 KB, free: 707.9 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_3_piece0
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on localhost:61325 (size: 23.8 KB, free: 707.9 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24404) called with curMem=1223624, maxMem=742328893
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_1_piece0
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.8 KB, free 706.7 MB)
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on localhost:61325 (size: 23.8 KB, free: 707.9 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_0_piece0
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24404) called with curMem=1248028, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.8 KB, free 706.7 MB)
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 1 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 3 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on localhost:61325 (size: 23.8 KB, free: 707.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_2_piece0
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 0 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 2 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293128) called with curMem=1272432, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 286.3 KB, free 706.4 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293128) called with curMem=1565560, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 286.3 KB, free 706.2 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293128) called with curMem=1858688, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 286.3 KB, free 705.9 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(293128) called with curMem=2151816, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 286.3 KB, free 705.6 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24256) called with curMem=2444944, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 23.7 KB, free 705.6 MB)
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on localhost:61325 (size: 23.7 KB, free: 707.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_6_piece0
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24256) called with curMem=2469200, maxMem=742328893
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 6 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.7 KB, free 705.6 MB)
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24256) called with curMem=2493456, maxMem=742328893
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 23.7 KB, free 705.5 MB)
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on localhost:61325 (size: 23.7 KB, free: 707.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_7_piece0
15/06/05 09:31:03 INFO storage.MemoryStore: ensureFreeSpace(24256) called with curMem=2517712, maxMem=742328893
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on localhost:61325 (size: 23.7 KB, free: 707.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_4_piece0
15/06/05 09:31:03 INFO storage.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 23.7 KB, free 705.5 MB)
15/06/05 09:31:03 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on localhost:61325 (size: 23.7 KB, free: 707.8 MB)
15/06/05 09:31:03 INFO storage.BlockManagerMaster: Updated info of block broadcast_5_piece0
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 7 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 4 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO spark.SparkContext: Created broadcast 5 from newAPIHadoopRDD at SparkDataSetProcessor.java:44
15/06/05 09:31:03 INFO util.RegionSizeCalculator: Calculating region sizes for table "80".
15/06/05 09:31:03 INFO util.RegionSizeCalculator: Calculating region sizes for table "80".
15/06/05 09:31:03 INFO util.RegionSizeCalculator: Calculating region sizes for table "80".
15/06/05 09:31:03 INFO util.RegionSizeCalculator: Calculating region sizes for table "80".
15/06/05 09:31:04 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:04 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:04 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:04 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:04 INFO util.RegionSizeCalculator: Calculating region sizes for table "32".
15/06/05 09:31:04 INFO util.RegionSizeCalculator: Calculating region sizes for table "32".
15/06/05 09:31:04 INFO util.RegionSizeCalculator: Calculating region sizes for table "32".
15/06/05 09:31:04 INFO util.RegionSizeCalculator: Calculating region sizes for table "32".
15/06/05 09:31:05 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:05 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:05 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:05 WARN mapreduce.TableInputFormatBase: Cannot resolve the host name for /192.168.0.83 because of javax.naming.NameNotFoundException: DNS name not found [response code 3]; remaining name '83.0.168.192.in-addr.arpa'
15/06/05 09:31:05 INFO spark.SparkContext: Starting job: hasNext at NLJInnerJoinFunction.java:60
15/06/05 09:31:05 INFO spark.SparkContext: Starting job: hasNext at NLJInnerJoinFunction.java:60
15/06/05 09:31:05 INFO spark.SparkContext: Starting job: hasNext at NLJInnerJoinFunction.java:60
15/06/05 09:31:05 INFO spark.SparkContext: Starting job: hasNext at NLJInnerJoinFunction.java:60
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 12 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 27 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Got job 3 (hasNext at NLJInnerJoinFunction.java:60) with 1 output partitions (allowLocal=false)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Final stage: Stage 2(hasNext at NLJInnerJoinFunction.java:60)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 0, Stage 1)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Missing parents: List(Stage 0, Stage 1)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting Stage 0 (MappedRDD[12] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(35656) called with curMem=2541968, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 34.8 KB, free 705.5 MB)
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(12519) called with curMem=2577624, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 12.2 KB, free 705.5 MB)
15/06/05 09:31:05 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on localhost:61325 (size: 12.2 KB, free: 707.7 MB)
15/06/05 09:31:05 INFO storage.BlockManagerMaster: Updated info of block broadcast_8_piece0
15/06/05 09:31:05 INFO spark.SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 0 (MappedRDD[12] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
15/06/05 09:31:05 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_0 tasks to pool default
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting Stage 1 (MappedRDD[27] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(32328) called with curMem=2590143, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 31.6 KB, free 705.4 MB)
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(12286) called with curMem=2622471, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 12.0 KB, free 705.4 MB)
15/06/05 09:31:05 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on localhost:61325 (size: 12.0 KB, free: 707.7 MB)
15/06/05 09:31:05 INFO storage.BlockManagerMaster: Updated info of block broadcast_9_piece0
15/06/05 09:31:05 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 1 (MappedRDD[27] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.TaskSchedulerImpl: Adding task set 1.0 with 1 tasks
15/06/05 09:31:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, ANY, 1273 bytes)
15/06/05 09:31:05 INFO executor.Executor: Running task 0.0 in stage 0.0 (TID 0)
15/06/05 09:31:05 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_1 tasks to pool default
15/06/05 09:31:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, ANY, 1273 bytes)
15/06/05 09:31:05 INFO executor.Executor: Running task 0.0 in stage 1.0 (TID 1)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 13 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 25 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Got job 2 (hasNext at NLJInnerJoinFunction.java:60) with 1 output partitions (allowLocal=false)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Final stage: Stage 5(hasNext at NLJInnerJoinFunction.java:60)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 3, Stage 4)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Missing parents: List(Stage 3, Stage 4)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting Stage 3 (MappedRDD[13] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(35904) called with curMem=2634757, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 35.1 KB, free 705.4 MB)
15/06/05 09:31:05 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(12526) called with curMem=2670661, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 12.2 KB, free 705.4 MB)
15/06/05 09:31:05 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on localhost:61325 (size: 12.2 KB, free: 707.7 MB)
15/06/05 09:31:05 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:05 INFO storage.BlockManagerMaster: Updated info of block broadcast_10_piece0
15/06/05 09:31:05 INFO spark.SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 3 (MappedRDD[13] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 WARN regionserver.HRegionFileSystem: .regioninfo file not found for region: cc7413cbc3ec28a1dce752093b78d657
15/06/05 09:31:05 INFO scheduler.TaskSchedulerImpl: Adding task set 3.0 with 1 tasks
15/06/05 09:31:05 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_3 tasks to pool default
15/06/05 09:31:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2, localhost, ANY, 1273 bytes)
15/06/05 09:31:05 INFO executor.Executor: Running task 0.0 in stage 3.0 (TID 2)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting Stage 4 (MappedRDD[25] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:05 WARN regionserver.HRegionFileSystem: .regioninfo file not found for region: 216d2188cbc71e48b40456c5708193ba
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(32496) called with curMem=2683187, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 31.7 KB, free 705.4 MB)
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(12279) called with curMem=2715683, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 12.0 KB, free 705.3 MB)
15/06/05 09:31:05 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on localhost:61325 (size: 12.0 KB, free: 707.7 MB)
15/06/05 09:31:05 INFO storage.BlockManagerMaster: Updated info of block broadcast_11_piece0
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 4 (MappedRDD[25] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
15/06/05 09:31:05 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_4 tasks to pool default
15/06/05 09:31:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3, localhost, ANY, 1273 bytes)
15/06/05 09:31:05 INFO executor.Executor: Running task 0.0 in stage 4.0 (TID 3)
15/06/05 09:31:05 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:05 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 14 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Registering RDD 26 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Got job 1 (hasNext at NLJInnerJoinFunction.java:60) with 1 output partitions (allowLocal=false)
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Final stage: Stage 8(hasNext at NLJInnerJoinFunction.java:60)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 6, Stage 7)
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Missing parents: List(Stage 6, Stage 7)
15/06/05 09:31:05 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:05 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting Stage 6 (MappedRDD[14] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(35408) called with curMem=2727962, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 34.6 KB, free 705.3 MB)
15/06/05 09:31:05 INFO storage.MemoryStore: ensureFreeSpace(12530) called with curMem=2763370, maxMem=742328893
15/06/05 09:31:05 INFO storage.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 12.2 KB, free 705.3 MB)
15/06/05 09:31:05 INFO regionserver.HStore: Closed V
15/06/05 09:31:05 INFO regionserver.HStore: Closed V
15/06/05 09:31:05 INFO regionserver.HStore: Closed V
15/06/05 09:31:05 INFO regionserver.HRegion: Closed 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657.
15/06/05 09:31:05 INFO regionserver.HStore: Closed V
15/06/05 09:31:05 INFO regionserver.HRegion: Closed 32,,1433432664138.216d2188cbc71e48b40456c5708193ba.
15/06/05 09:31:05 INFO regionserver.HRegion: Closed 32,,1433432664138.216d2188cbc71e48b40456c5708193ba.
15/06/05 09:31:05 WARN regionserver.HRegion: Region 32,,1433432664138.216d2188cbc71e48b40456c5708193ba. already closed
15/06/05 09:31:05 WARN regionserver.HRegion: Region 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657. already closed
15/06/05 09:31:05 INFO regionserver.HRegion: Closed 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657.
15/06/05 09:31:05 WARN regionserver.HRegion: Region 32,,1433432664138.216d2188cbc71e48b40456c5708193ba. already closed
15/06/05 09:31:05 WARN regionserver.HRegion: Region 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657. already closed
15/06/05 09:31:05 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on localhost:61325 (size: 12.2 KB, free: 707.7 MB)
15/06/05 09:31:05 INFO storage.BlockManagerMaster: Updated info of block broadcast_12_piece0
15/06/05 09:31:05 INFO spark.SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:05 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 6 (MappedRDD[14] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:05 INFO scheduler.TaskSchedulerImpl: Adding task set 6.0 with 1 tasks
15/06/05 09:31:05 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_6 tasks to pool default
15/06/05 09:31:05 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4, localhost, ANY, 1273 bytes)
15/06/05 09:31:06 INFO executor.Executor: Running task 0.0 in stage 6.0 (TID 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting Stage 7 (MappedRDD[26] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(32168) called with curMem=2775900, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 31.4 KB, free 705.3 MB)
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(12282) called with curMem=2808068, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 12.0 KB, free 705.3 MB)
15/06/05 09:31:06 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on localhost:61325 (size: 12.0 KB, free: 707.7 MB)
15/06/05 09:31:06 INFO storage.BlockManagerMaster: Updated info of block broadcast_13_piece0
15/06/05 09:31:06 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 7 (MappedRDD[26] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 3). 1914 bytes result sent to driver
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 0.0 (TID 0). 1959 bytes result sent to driver
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 3.0 (TID 2). 1959 bytes result sent to driver
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 1.0 (TID 1). 1914 bytes result sent to driver
15/06/05 09:31:06 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_7 tasks to pool default
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5, localhost, ANY, 1273 bytes)
15/06/05 09:31:06 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 5)
15/06/05 09:31:06 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Registering RDD 15 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Registering RDD 24 (keyBy at SparkDataSet.java:85)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Got job 0 (hasNext at NLJInnerJoinFunction.java:60) with 1 output partitions (allowLocal=false)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Final stage: Stage 11(hasNext at NLJInnerJoinFunction.java:60)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Parents of final stage: List(Stage 9, Stage 10)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents: List(Stage 9, Stage 10)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting Stage 9 (MappedRDD[15] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(35680) called with curMem=2820350, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 34.8 KB, free 705.2 MB)
15/06/05 09:31:06 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 816 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(12529) called with curMem=2856030, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 12.2 KB, free 705.2 MB)
15/06/05 09:31:06 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on localhost:61325 (size: 12.2 KB, free: 707.7 MB)
15/06/05 09:31:06 INFO storage.BlockManagerMaster: Updated info of block broadcast_14_piece0
15/06/05 09:31:06 INFO spark.SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 9 (MappedRDD[15] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 863 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HStore: Closed V
15/06/05 09:31:06 INFO regionserver.HRegion: Closed 32,,1433432664138.216d2188cbc71e48b40456c5708193ba.
15/06/05 09:31:06 WARN regionserver.HRegion: Region 32,,1433432664138.216d2188cbc71e48b40456c5708193ba. already closed
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 880 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 816 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_9 tasks to pool default
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6, localhost, ANY, 1273 bytes)
15/06/05 09:31:06 INFO executor.Executor: Running task 0.0 in stage 9.0 (TID 6)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting Stage 10 (MappedRDD[24] at keyBy at SparkDataSet.java:85), which has no missing parents
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 6.0 (TID 4). 1959 bytes result sent to driver
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(32344) called with curMem=2868559, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 31.6 KB, free 705.2 MB)
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 852 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO regionserver.HStore: Closed V
15/06/05 09:31:06 INFO regionserver.HRegion: Closed 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657.
15/06/05 09:31:06 WARN regionserver.HRegion: Region 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657. already closed
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(12275) called with curMem=2900903, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 12.0 KB, free 705.2 MB)
15/06/05 09:31:06 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on localhost:61325 (size: 12.0 KB, free: 707.7 MB)
15/06/05 09:31:06 INFO storage.BlockManagerMaster: Updated info of block broadcast_15_piece0
15/06/05 09:31:06 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 10 (MappedRDD[24] at keyBy at SparkDataSet.java:85)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
15/06/05 09:31:06 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_10 tasks to pool default
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7, localhost, ANY, 1273 bytes)
15/06/05 09:31:06 INFO executor.Executor: Running task 0.0 in stage 10.0 (TID 7)
15/06/05 09:31:06 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 5). 1914 bytes result sent to driver
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:06 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Stage 3 (keyBy at SparkDataSet.java:85) finished in 1.015 s
15/06/05 09:31:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:06 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 203 ms on localhost (1/1)
15/06/05 09:31:06 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool default
15/06/05 09:31:06 INFO scheduler.DAGScheduler: running: Set(Stage 0, Stage 9, Stage 1, Stage 6, Stage 10, Stage 7, Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: waiting: Set(Stage 5, Stage 2, Stage 11, Stage 8)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined 216d2188cbc71e48b40456c5708193ba; next sequenceid=1
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 5: List(Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 2: List(Stage 0, Stage 1)
15/06/05 09:31:06 INFO regionserver.HStore: Closed V
15/06/05 09:31:06 INFO regionserver.HRegion: Closed 32,,1433432664138.216d2188cbc71e48b40456c5708193ba.
15/06/05 09:31:06 WARN regionserver.HRegion: Region 32,,1433432664138.216d2188cbc71e48b40456c5708193ba. already closed
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List(Stage 6, Stage 7)
15/06/05 09:31:06 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:31:06 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Stage 1 (keyBy at SparkDataSet.java:85) finished in 1.066 s
15/06/05 09:31:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:06 INFO scheduler.DAGScheduler: running: Set(Stage 0, Stage 9, Stage 6, Stage 10, Stage 7, Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: waiting: Set(Stage 5, Stage 2, Stage 11, Stage 8)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 5: List(Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 2: List(Stage 0)
15/06/05 09:31:06 INFO regionserver.HStore: Closed V
15/06/05 09:31:06 INFO regionserver.HRegion: Closed 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657.
15/06/05 09:31:06 WARN regionserver.HRegion: Region 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657. already closed
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List(Stage 6, Stage 7)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Stage 0 (keyBy at SparkDataSet.java:85) finished in 1.096 s
15/06/05 09:31:06 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:06 INFO scheduler.DAGScheduler: running: Set(Stage 9, Stage 6, Stage 10, Stage 7, Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: waiting: Set(Stage 5, Stage 2, Stage 11, Stage 8)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 5: List(Stage 4)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 2: List()
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List(Stage 6, Stage 7)
15/06/05 09:31:06 INFO scheduler.DAGScheduler: Submitting Stage 2 (FlatMappedRDD[48] at flatMap at SparkDataSet.java:120), which is now runnable
15/06/05 09:31:06 INFO storage.MemoryStore: ensureFreeSpace(32264) called with curMem=2913178, maxMem=742328893
15/06/05 09:31:06 INFO storage.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 31.5 KB, free 705.1 MB)
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 9.0 (TID 6). 1959 bytes result sent to driver
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 10.0 (TID 7). 1914 bytes result sent to driver
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(12037) called with curMem=2945442, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 11.8 KB, free 705.1 MB)
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on localhost:61325 (size: 11.8 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_16_piece0
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 1653 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO spark.SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 2 (FlatMappedRDD[48] at flatMap at SparkDataSet.java:120)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 1580 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_2 tasks to pool default
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 8, localhost, PROCESS_LOCAL, 1902 bytes)
15/06/05 09:31:08 INFO executor.Executor: Running task 0.0 in stage 2.0 (TID 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 4 (keyBy at SparkDataSet.java:85) finished in 2.504 s
15/06/05 09:31:08 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:08 INFO scheduler.DAGScheduler: running: Set(Stage 9, Stage 2, Stage 6, Stage 10, Stage 7)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: waiting: Set(Stage 5, Stage 11, Stage 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 5: List()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List(Stage 6, Stage 7)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting Stage 5 (FlatMappedRDD[51] at flatMap at SparkDataSet.java:120), which is now runnable
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(32424) called with curMem=2957479, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 31.7 KB, free 705.1 MB)
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(12035) called with curMem=2989903, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 11.8 KB, free 705.1 MB)
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on localhost:61325 (size: 11.8 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_17_piece0
15/06/05 09:31:08 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 5 (FlatMappedRDD[51] at flatMap at SparkDataSet.java:120)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
15/06/05 09:31:08 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_5 tasks to pool default
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 9, localhost, PROCESS_LOCAL, 1902 bytes)
15/06/05 09:31:08 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 9)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 6 (keyBy at SparkDataSet.java:85) finished in 2.476 s
15/06/05 09:31:08 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:08 INFO scheduler.DAGScheduler: running: Set(Stage 9, Stage 5, Stage 2, Stage 10, Stage 7)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: waiting: Set(Stage 11, Stage 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List(Stage 7)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 7 (keyBy at SparkDataSet.java:85) finished in 1.751 s
15/06/05 09:31:08 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:08 INFO scheduler.DAGScheduler: running: Set(Stage 9, Stage 5, Stage 2, Stage 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: waiting: Set(Stage 11, Stage 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 9, Stage 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 8: List()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting Stage 8 (FlatMappedRDD[49] at flatMap at SparkDataSet.java:120), which is now runnable
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(32096) called with curMem=3001938, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 31.3 KB, free 705.0 MB)
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(12024) called with curMem=3034034, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 11.7 KB, free 705.0 MB)
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on localhost:61325 (size: 11.7 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_18_piece0
15/06/05 09:31:08 INFO spark.SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 8 (FlatMappedRDD[49] at flatMap at SparkDataSet.java:120)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Adding task set 8.0 with 1 tasks
15/06/05 09:31:08 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_8 tasks to pool default
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 9 (keyBy at SparkDataSet.java:85) finished in 1.717 s
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10, localhost, PROCESS_LOCAL, 1902 bytes)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:08 INFO scheduler.DAGScheduler: running: Set(Stage 5, Stage 2, Stage 10, Stage 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: waiting: Set(Stage 11)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:08 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List(Stage 10)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 10 (keyBy at SparkDataSet.java:85) finished in 1.642 s
15/06/05 09:31:08 INFO scheduler.DAGScheduler: looking for newly runnable stages
15/06/05 09:31:08 INFO scheduler.DAGScheduler: running: Set(Stage 5, Stage 2, Stage 8)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: waiting: Set(Stage 11)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: failed: Set()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Missing parents for Stage 11: List()
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting Stage 11 (FlatMappedRDD[50] at flatMap at SparkDataSet.java:120), which is now runnable
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(32280) called with curMem=3046058, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 31.5 KB, free 705.0 MB)
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/06/05 09:31:08 INFO storage.MemoryStore: ensureFreeSpace(12027) called with curMem=3078338, maxMem=742328893
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 11.7 KB, free 705.0 MB)
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on localhost:61325 (size: 11.7 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_19_piece0
15/06/05 09:31:08 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:838
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from Stage 11 (FlatMappedRDD[50] at flatMap at SparkDataSet.java:120)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Adding task set 11.0 with 1 tasks
15/06/05 09:31:08 INFO scheduler.FairSchedulableBuilder: Added task set TaskSet_11 tasks to pool default
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 11.0 (TID 11, localhost, PROCESS_LOCAL, 1902 bytes)
15/06/05 09:31:08 INFO executor.Executor: Running task 0.0 in stage 11.0 (TID 11)
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Getting 0 non-empty blocks out of 1 blocks
15/06/05 09:31:08 INFO storage.ShuffleBlockFetcherIterator: Started 0 remote fetches in 2 ms
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 5.0 (TID 9). 802 bytes result sent to driver
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 9) in 208 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 5 (hasNext at NLJInnerJoinFunction.java:60) finished in 0.216 s
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 8.0 (TID 10). 802 bytes result sent to driver
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Job 2 finished: hasNext at NLJInnerJoinFunction.java:60, took 2.883641 s
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 2.0 (TID 8). 802 bytes result sent to driver
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 11.0 (TID 11). 802 bytes result sent to driver
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 197 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 8 (hasNext at NLJInnerJoinFunction.java:60) finished in 0.427 s
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Job 1 finished: hasNext at NLJInnerJoinFunction.java:60, took 3.112684 s
15/06/05 09:31:08 INFO storage.BlockManager: Removing broadcast 17
15/06/05 09:31:08 INFO storage.BlockManager: Removing block broadcast_17_piece0
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_17_piece0 of size 12035 dropped from memory (free 739250563)
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 8) in 478 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 2 (hasNext at NLJInnerJoinFunction.java:60) finished in 0.505 s
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Job 3 finished: hasNext at NLJInnerJoinFunction.java:60, took 3.140566 s
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Removed broadcast_17_piece0 on localhost:61325 in memory (size: 11.8 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_17_piece0
15/06/05 09:31:08 INFO storage.BlockManager: Removing block broadcast_17
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_17 of size 32424 dropped from memory (free 739282987)
15/06/05 09:31:08 INFO spark.ContextCleaner: Cleaned broadcast 17
15/06/05 09:31:08 INFO storage.BlockManager: Removing broadcast 18
15/06/05 09:31:08 INFO storage.BlockManager: Removing block broadcast_18_piece0
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_18_piece0 of size 12024 dropped from memory (free 739295011)
15/06/05 09:31:08 INFO storage.BlockManagerInfo: Removed broadcast_18_piece0 on localhost:61325 in memory (size: 11.7 KB, free: 707.6 MB)
15/06/05 09:31:08 INFO storage.BlockManagerMaster: Updated info of block broadcast_18_piece0
15/06/05 09:31:08 INFO storage.BlockManager: Removing block broadcast_18
15/06/05 09:31:08 INFO storage.MemoryStore: Block broadcast_18 of size 32096 dropped from memory (free 739327107)
15/06/05 09:31:08 INFO spark.ContextCleaner: Cleaned broadcast 18
15/06/05 09:31:08 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 11.0 (TID 11) in 429 ms on localhost (1/1)
15/06/05 09:31:08 INFO scheduler.TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool default
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Stage 11 (hasNext at NLJInnerJoinFunction.java:60) finished in 0.439 s
15/06/05 09:31:08 INFO scheduler.DAGScheduler: Job 0 finished: hasNext at NLJInnerJoinFunction.java:60, took 3.151508 s
15/06/05 09:31:08 INFO executor.Executor: Finished task 0.0 in stage 4.0 (TID 16). 1529 bytes result sent to driver
15/06/05 09:31:09 INFO executor.Executor: Finished task 3.0 in stage 4.0 (TID 19). 1529 bytes result sent to driver
15/06/05 09:31:09 INFO executor.Executor: Finished task 2.0 in stage 4.0 (TID 18). 1529 bytes result sent to driver
15/06/05 09:31:09 INFO executor.Executor: Finished task 1.0 in stage 4.0 (TID 17). 1529 bytes result sent to driver
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 20
15/06/05 09:31:09 INFO executor.Executor: Running task 0.0 in stage 5.0 (TID 20)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 21
15/06/05 09:31:09 INFO executor.Executor: Running task 1.0 in stage 5.0 (TID 21)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 22
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 23
15/06/05 09:31:09 INFO executor.Executor: Running task 2.0 in stage 5.0 (TID 22)
15/06/05 09:31:09 INFO executor.Executor: Running task 3.0 in stage 5.0 (TID 23)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 1.0 in stage 5.0 (TID 21)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 3.0 in stage 5.0 (TID 23)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 0.0 in stage 5.0 (TID 20)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 2.0 in stage 5.0 (TID 22)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 24
15/06/05 09:31:09 INFO executor.Executor: Running task 1.1 in stage 5.0 (TID 24)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 25
15/06/05 09:31:09 INFO executor.Executor: Running task 2.1 in stage 5.0 (TID 25)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 26
15/06/05 09:31:09 INFO executor.Executor: Running task 0.1 in stage 5.0 (TID 26)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 27
15/06/05 09:31:09 INFO executor.Executor: Running task 3.1 in stage 5.0 (TID 27)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 2.1 in stage 5.0 (TID 25)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 0.1 in stage 5.0 (TID 26)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 3.1 in stage 5.0 (TID 27)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 1.1 in stage 5.0 (TID 24)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 28
15/06/05 09:31:09 INFO executor.Executor: Running task 2.2 in stage 5.0 (TID 28)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 2.2 in stage 5.0 (TID 28)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 29
15/06/05 09:31:09 INFO executor.Executor: Running task 0.2 in stage 5.0 (TID 29)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 0.2 in stage 5.0 (TID 29)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 30
15/06/05 09:31:09 INFO executor.Executor: Running task 1.2 in stage 5.0 (TID 30)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 31
15/06/05 09:31:09 INFO executor.Executor: Running task 3.2 in stage 5.0 (TID 31)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 1.2 in stage 5.0 (TID 30)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 3.2 in stage 5.0 (TID 31)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 32
15/06/05 09:31:09 INFO executor.Executor: Running task 0.3 in stage 5.0 (TID 32)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 33
15/06/05 09:31:09 INFO executor.Executor: Running task 2.3 in stage 5.0 (TID 33)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 0.3 in stage 5.0 (TID 32)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 2.3 in stage 5.0 (TID 33)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 34
15/06/05 09:31:09 INFO executor.Executor: Running task 3.3 in stage 5.0 (TID 34)
15/06/05 09:31:09 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 35
15/06/05 09:31:09 INFO executor.Executor: Running task 1.3 in stage 5.0 (TID 35)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 1.3 in stage 5.0 (TID 35)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:31:09 ERROR executor.Executor: Exception in task 3.3 in stage 5.0 (TID 34)
java.lang.ClassCastException: org.apache.spark.SerializableWritable cannot be cast to [B
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:61)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:32:01 INFO storage.BlockManager: Removing broadcast 6
15/06/05 09:32:01 INFO storage.BlockManager: Removing block broadcast_6_piece0
15/06/05 09:32:01 INFO storage.MemoryStore: Block broadcast_6_piece0 of size 14158 dropped from memory (free 740485066)
15/06/05 09:32:01 INFO storage.BlockManagerMaster: Updated info of block broadcast_6_piece0
15/06/05 09:32:01 INFO storage.BlockManager: Removing block broadcast_6
15/06/05 09:32:01 INFO storage.MemoryStore: Block broadcast_6 of size 63112 dropped from memory (free 740548178)
15/06/05 09:32:01 INFO storage.BlockManager: Removing broadcast 7
15/06/05 09:34:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 36
15/06/05 09:34:23 INFO executor.Executor: Running task 0.0 in stage 7.0 (TID 36)
15/06/05 09:34:23 INFO rdd.NewHadoopRDD: Input split: 192.168.0.83:,
15/06/05 09:34:23 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:34:23 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:34:23 INFO compactions.CompactionConfiguration: size [134217728, 9223372036854775807); files [3, 10); ratio 1.200000; off-peak ratio 5.000000; throttle point 2684354560; delete expired; major period 604800000, major jitter 0.500000
15/06/05 09:34:23 INFO regionserver.HRegion: Onlined cc7413cbc3ec28a1dce752093b78d657; next sequenceid=1
15/06/05 09:34:23 INFO regionserver.HStore: Closed V
15/06/05 09:34:23 INFO regionserver.HRegion: Closed 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657.
15/06/05 09:34:23 WARN regionserver.HRegion: Region 80,,1433432664142.cc7413cbc3ec28a1dce752093b78d657. already closed
15/06/05 09:34:23 INFO executor.Executor: Finished task 0.0 in stage 7.0 (TID 36). 1914 bytes result sent to driver
15/06/05 09:34:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 37
15/06/05 09:34:23 INFO executor.Executor: Running task 0.0 in stage 8.0 (TID 37)
15/06/05 09:34:23 INFO spark.MapOutputTrackerWorker: Updating epoch to 1 and clearing cache
15/06/05 09:34:23 ERROR executor.Executor: Exception in task 0.0 in stage 8.0 (TID 37)
java.lang.ClassCastException: org.apache.spark.ShuffleDependency cannot be cast to scala.Function2
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:34:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 38
15/06/05 09:34:23 INFO executor.Executor: Running task 0.1 in stage 8.0 (TID 38)
15/06/05 09:34:23 ERROR executor.Executor: Exception in task 0.1 in stage 8.0 (TID 38)
java.lang.ClassCastException: org.apache.spark.ShuffleDependency cannot be cast to scala.Function2
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:34:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 39
15/06/05 09:34:23 INFO executor.Executor: Running task 0.2 in stage 8.0 (TID 39)
15/06/05 09:34:23 ERROR executor.Executor: Exception in task 0.2 in stage 8.0 (TID 39)
java.lang.ClassCastException: org.apache.spark.ShuffleDependency cannot be cast to scala.Function2
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:34:23 INFO executor.CoarseGrainedExecutorBackend: Got assigned task 40
15/06/05 09:34:23 INFO executor.Executor: Running task 0.3 in stage 8.0 (TID 40)
15/06/05 09:34:23 ERROR executor.Executor: Exception in task 0.3 in stage 8.0 (TID 40)
java.lang.ClassCastException: org.apache.spark.ShuffleDependency cannot be cast to scala.Function2
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:57)
	at org.apache.spark.scheduler.Task.run(Task.scala:56)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:196)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
15/06/05 09:35:28 INFO storage.BlockManager: Removing broadcast 9
15/06/05 09:35:28 INFO storage.BlockManager: Removing broadcast 10
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90014, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90013, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90016, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90015, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90017, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90012, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90011, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Unable to read additional data from server sessionid 0x14dc41d88c90018, likely server has closed socket, closing socket connection and attempting reconnect
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:06 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90018 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:06 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90015 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:06 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:06 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90014 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:07 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:07 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90017 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:07 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:07 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:07 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:07 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90013 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:07 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:07 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90012 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:07 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:07 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90016 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:08 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:08 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90018 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:08 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:08 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90011 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:08 INFO zookeeper.ClientCnxn: Opening socket connection to server localhost/127.0.0.1:2181. Will not attempt to authenticate using SASL (unknown error)
15/06/05 09:37:08 WARN zookeeper.ClientCnxn: Session 0x14dc41d88c90015 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1081)
15/06/05 09:37:08 ERROR executor.CoarseGrainedExecutorBackend: RECEIVED SIGNAL 2: SIGINT
