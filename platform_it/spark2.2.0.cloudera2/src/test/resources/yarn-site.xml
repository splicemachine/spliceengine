<!--
  ~ Copyright (c) 2012 - 2017 Splice Machine, Inc.
  ~
  ~ This file is part of Splice Machine.
  ~ Splice Machine is free software: you can redistribute it and/or modify it under the terms of the
  ~ GNU Affero General Public License as published by the Free Software Foundation, either
  ~ version 3, or (at your option) any later version.
  ~ Splice Machine is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY;
  ~ without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
  ~ See the GNU Affero General Public License for more details.
  ~ You should have received a copy of the GNU Affero General Public License along with Splice Machine.
  ~ If not, see <http://www.gnu.org/licenses/>.
  -->

<configuration>
  <property>
    <!-- Don't let minicluster overwrite ports we set in here -->
    <name>yarn.minicluster.fixed.ports</name>
    <value>true</value>
    <description>Don't let minicluster overwrite ports we set in here</description>
  </property>
  <property>
    <name>yarn.resourcemanager.webapp.address</name>
    <value>localhost:8080</value>
    <description>Connect to resource manager web page.</description>
  </property>

  <property>
    <name>yarn.resourcemanager.bind-host</name>
    <value>0.0.0.0</value>
  </property>
  <property>
    <name>yarn.nodemanager.hostname</name>
    <value>localhost</value>
  </property>
  <property>
    <name>yarn.nodemanager.scheduler.address</name>
    <value>localhost:8050</value>
  </property>
  <property>
    <name>yarn.nodemanager.address</name>
    <value>localhost:8053</value>
  </property>
  <property>
    <name>yarn.resourcemanager.hostname</name>
    <value>localhost</value>
  </property>
  <property>
    <name>yarn.resourcemanager.scheduler.address</name>
    <value>localhost:8030</value>
  </property>
  <property>
    <name>yarn.resourcemanager.resource-tracker.address</name>
    <value>localhost:8031</value>
  </property>
  <property>
    <name>yarn.resourcemanager.address</name>
    <value>localhost:8032</value>
  </property>
  <property>
    <name>yarn.resourcemanager.admin.address</name>
    <value>localhost:8033</value>
  </property>
  <property>
    <name>yarn.nodemanager.aux-services</name>
    <value>spark_shuffle</value>
  </property>

  <property>
    <name>yarn.nodemanager.aux-services.spark_shuffle.class</name>
    <value>org.apache.spark.network.yarn.YarnShuffleService</value>
  </property>
  
  <property>
    <name>spark.shuffle.service.port</name>
    <value>8061</value>
  </property>

  <property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>128</value>
    <description>Minimum limit of memory to allocate to each container request at the Resource Manager.</description>
  </property>
  <property>
    <name>yarn.scheduler.minimum-allocation-mb</name>
    <value>128</value>
    <description>Minimum limit of memory to allocate to each container request at the Resource Manager.</description>
  </property>
  <property>
    <name>yarn.scheduler.maximum-allocation-mb</name>
    <value>5793</value>
    <description>Maximum limit of memory to allocate to each container request at the Resource Manager.</description>
  </property>
  <property>
    <name>yarn.scheduler.minimum-allocation-vcores</name>
    <value>1</value>
    <description>The minimum allocation for every container request at the RM, in terms of virtual CPU cores. Requests
      lower than this won't take effect, and the specified value will get allocated the minimum.
    </description>
  </property>
  <property>
    <name>yarn.scheduler.maximum-allocation-vcores</name>
    <value>4</value>
    <description>The maximum allocation for every container request at the RM, in terms of virtual CPU cores. Requests
      higher than this won't take effect, and will get capped to this value.
    </description>
  </property>
  <property>
    <name>yarn.nodemanager.resource.memory-mb</name>
    <value>8192</value>
    <description>Physical memory, in MB, to be made available to running containers</description>
  </property>
  <property>
    <name>yarn.nodemanager.resource.cpu-vcores</name>
    <value>4</value>
    <description>Number of CPU cores that can be allocated for containers.</description>
  </property>
  <property>
    <name>yarn.nodemanager.disk-health-checker.enable</name>
    <value>false</value>
  </property>
  <property>
    <name>yarn.nodemanager.dist-health-checker.max-disk-utilization-per-disk-percentage</name>
    <value>100</value>
  </property>
</configuration>
